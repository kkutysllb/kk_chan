#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼ è®ºå¤šå‘¨æœŸåˆ†æå™¨
å®ç°å¤šå‘¨æœŸè”ç«‹åˆ†æï¼Œè¯†åˆ«æ¬¡çº§è¶‹åŠ¿ä¸ä¸Šä¸€çº§è¶‹åŠ¿çš„å…³ç³»
"""

from datetime import datetime
from typing import Dict, List, Optional, Tuple
import pandas as pd
import numpy as np

import sys
import os

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
chan_theory_dir = os.path.dirname(current_dir)
sys.path.append(chan_theory_dir)

try:
    from models.chan_theory_models import (
        TrendLevel, FenXing, Bi, XianDuan, ZhongShu, BollingerBands,
        FenXingType, TrendDirection, ChanTheoryConfig
    )
    from analyzers.structure_analyzer import ChanStructureAnalyzer
except ImportError:
    from analysis.chan_theory.models.chan_theory_models import (
        TrendLevel, FenXing, Bi, XianDuan, ZhongShu, BollingerBands,
        FenXingType, TrendDirection, ChanTheoryConfig
    )
    from analysis.chan_theory.analyzers.structure_analyzer import ChanStructureAnalyzer


class MultiTimeframeAnalyzer:
    """å¤šå‘¨æœŸç¼ è®ºåˆ†æå™¨"""
    
    def __init__(self, config: ChanTheoryConfig):
        """åˆå§‹åŒ–å¤šå‘¨æœŸåˆ†æå™¨"""
        self.config = config
        self.structure_analyzers = {}
        
        # ä¸ºæ¯ä¸ªå‘¨æœŸåˆ›å»ºç»“æ„åˆ†æå™¨
        for level in TrendLevel:
            self.structure_analyzers[level] = ChanStructureAnalyzer(config, level)
        
        print("ğŸ” å¤šå‘¨æœŸç¼ è®ºåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def analyze_multi_timeframe_trend(self, multi_data: Dict[TrendLevel, pd.DataFrame]) -> Dict[str, any]:
        """
        å¤šå‘¨æœŸè”ç«‹è¶‹åŠ¿åˆ†æ
        
        Args:
            multi_data: å¤šå‘¨æœŸæ•°æ®
            
        Returns:
            å¤šå‘¨æœŸåˆ†æç»“æœ
        """
        print("ğŸ” å¼€å§‹å¤šå‘¨æœŸè”ç«‹è¶‹åŠ¿åˆ†æ...")
        
        # å„å‘¨æœŸåˆ†æç»“æœ
        level_results = {}
        
        # åˆ†æå„ä¸ªå‘¨æœŸ
        for level, data in multi_data.items():
            if data.empty:
                continue
                
            print(f"\nğŸ“Š åˆ†æ {level.value} çº§åˆ«...")
            
            # ç¡®ä¿è¯¥å‘¨æœŸçš„åˆ†æå™¨å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
            if level not in self.structure_analyzers:
                self.structure_analyzers[level] = ChanStructureAnalyzer(self.config, level)
            
            analyzer = self.structure_analyzers[level]
            
            # å•å‘¨æœŸåˆ†æ
            level_result = analyzer.analyze_single_timeframe(data)
            level_results[level] = level_result
            
            print(f"âœ… {level.value} çº§åˆ«åˆ†æå®Œæˆ")
        
        # å¤šå‘¨æœŸè”ç«‹åˆ†æ
        multi_analysis = self._perform_multi_timeframe_analysis(level_results)
        
        # è¶‹åŠ¿å…³ç³»åˆ†æ
        trend_relationships = self._analyze_trend_relationships(level_results)
        
        # ç»¼åˆè¯„ä¼°
        comprehensive_assessment = self._comprehensive_trend_assessment(
            level_results, multi_analysis, trend_relationships
        )
        
        result = {
            'level_results': level_results,
            'multi_analysis': multi_analysis,
            'trend_relationships': trend_relationships,
            'comprehensive_assessment': comprehensive_assessment,
            'analysis_time': datetime.now()
        }
        
        print("âœ… å¤šå‘¨æœŸè”ç«‹è¶‹åŠ¿åˆ†æå®Œæˆ")
        return result
    
    def _perform_multi_timeframe_analysis(self, level_results: Dict[TrendLevel, Dict]) -> Dict[str, any]:
        """æ‰§è¡Œå¤šå‘¨æœŸè”ç«‹åˆ†æ"""
        print("ğŸ” æ‰§è¡Œå¤šå‘¨æœŸè”ç«‹åˆ†æ...")
        
        # è¶‹åŠ¿æ–¹å‘ç»Ÿè®¡
        trend_directions = {}
        trend_strengths = {}
        zhongshu_levels = {}
        
        for level, result in level_results.items():
            if 'current_trend' in result:
                trend_directions[level] = result['current_trend']
                trend_strengths[level] = result.get('trend_strength', 0.5)
            
            if 'current_zhongshu' in result and result['current_zhongshu']:
                zhongshu_levels[level] = result['current_zhongshu']
        
        # è¶‹åŠ¿ä¸€è‡´æ€§åˆ†æ
        trend_consistency = self._calculate_trend_consistency(trend_directions)
        
        # ä¸»å¯¼è¶‹åŠ¿è¯†åˆ«
        dominant_trend = self._identify_dominant_trend(trend_directions, trend_strengths)
        
        # å…³é”®æ”¯æ’‘é˜»åŠ›ä½
        key_levels = self._identify_key_levels(level_results)
        
        return {
            'trend_directions': trend_directions,
            'trend_strengths': trend_strengths,
            'trend_consistency': trend_consistency,
            'dominant_trend': dominant_trend,
            'zhongshu_levels': zhongshu_levels,
            'key_support_levels': key_levels['support'],
            'key_resistance_levels': key_levels['resistance']
        }
    
    def _analyze_trend_relationships(self, level_results: Dict[TrendLevel, Dict]) -> Dict[str, any]:
        """
        åˆ†ææ¬¡çº§è¶‹åŠ¿ä¸ä¸Šä¸€çº§è¶‹åŠ¿çš„å…³ç³»
        
        åŸºäºç¼ è®ºç†è®ºï¼š
        1. æ¬¡çº§è¶‹åŠ¿æ˜¯å¯¹ä¸»è¦è¶‹åŠ¿çš„ä¿®æ­£
        2. æ¬¡çº§è¶‹åŠ¿é€šå¸¸æŒç»­æ—¶é—´è¾ƒçŸ­ï¼Œå¹…åº¦ä¸ºä¸»è¦è¶‹åŠ¿çš„1/3åˆ°2/3
        3. æ¬¡çº§è¶‹åŠ¿ç»“æŸåï¼Œä¸»è¦è¶‹åŠ¿é€šå¸¸ä¼šç»§ç»­
        """
        print("ğŸ” åˆ†æè¶‹åŠ¿çº§åˆ«å…³ç³»...")
        
        relationships = {}
        
        # æ—¥çº¿ä¸30åˆ†é’Ÿçš„å…³ç³»
        if TrendLevel.DAILY in level_results and TrendLevel.MIN30 in level_results:
            daily_result = level_results[TrendLevel.DAILY]
            min30_result = level_results[TrendLevel.MIN30]
            
            relationship = self._analyze_trend_pair_relationship(
                daily_result, min30_result, "æ—¥çº¿", "30åˆ†é’Ÿ"
            )
            relationships['daily_vs_30min'] = relationship
        
        # 30åˆ†é’Ÿä¸5åˆ†é’Ÿçš„å…³ç³»
        if TrendLevel.MIN30 in level_results and TrendLevel.MIN5 in level_results:
            min30_result = level_results[TrendLevel.MIN30]
            min5_result = level_results[TrendLevel.MIN5]
            
            relationship = self._analyze_trend_pair_relationship(
                min30_result, min5_result, "30åˆ†é’Ÿ", "5åˆ†é’Ÿ"
            )
            relationships['30min_vs_5min'] = relationship
        
        # æ—¥çº¿ä¸5åˆ†é’Ÿçš„å…³ç³»
        if TrendLevel.DAILY in level_results and TrendLevel.MIN5 in level_results:
            daily_result = level_results[TrendLevel.DAILY]
            min5_result = level_results[TrendLevel.MIN5]
            
            relationship = self._analyze_trend_pair_relationship(
                daily_result, min5_result, "æ—¥çº¿", "5åˆ†é’Ÿ"
            )
            relationships['daily_vs_5min'] = relationship
        
        return relationships
    
    def _analyze_trend_pair_relationship(self, higher_result: Dict, lower_result: Dict, 
                                       higher_name: str, lower_name: str) -> Dict[str, any]:
        """åˆ†æä¸¤ä¸ªçº§åˆ«ä¹‹é—´çš„è¶‹åŠ¿å…³ç³»"""
        
        higher_trend = higher_result.get('current_trend', TrendDirection.SIDEWAYS)
        lower_trend = lower_result.get('current_trend', TrendDirection.SIDEWAYS)
        
        # è¶‹åŠ¿ä¸€è‡´æ€§
        is_consistent = higher_trend == lower_trend
        
        # èƒŒç¦»æƒ…å†µ
        is_divergent = (higher_trend == TrendDirection.UP and lower_trend == TrendDirection.DOWN) or \
                      (higher_trend == TrendDirection.DOWN and lower_trend == TrendDirection.UP)
        
        # ä¿®æ­£å…³ç³»
        is_correction = False
        correction_type = None
        
        if higher_trend != TrendDirection.SIDEWAYS and lower_trend != TrendDirection.SIDEWAYS:
            if is_divergent:
                is_correction = True
                if higher_trend == TrendDirection.UP:
                    correction_type = "ä¸Šå‡è¶‹åŠ¿ä¸­çš„å›è°ƒä¿®æ­£"
                else:
                    correction_type = "ä¸‹é™è¶‹åŠ¿ä¸­çš„åå¼¹ä¿®æ­£"
        
        # å¼ºåº¦å¯¹æ¯”
        higher_strength = higher_result.get('trend_strength', 0.5)
        lower_strength = lower_result.get('trend_strength', 0.5)
        strength_ratio = lower_strength / higher_strength if higher_strength > 0 else 1.0
        
        # ä¸­æ¢å…³ç³»
        zhongshu_relationship = self._analyze_zhongshu_relationship(higher_result, lower_result)
        
        return {
            'higher_level': higher_name,
            'lower_level': lower_name,
            'higher_trend': higher_trend,
            'lower_trend': lower_trend,
            'is_consistent': is_consistent,
            'is_divergent': is_divergent,
            'is_correction': is_correction,
            'correction_type': correction_type,
            'strength_ratio': strength_ratio,
            'zhongshu_relationship': zhongshu_relationship,
            'relationship_quality': self._evaluate_relationship_quality(
                is_consistent, is_correction, strength_ratio
            )
        }
    
    def _analyze_zhongshu_relationship(self, higher_result: Dict, lower_result: Dict) -> Dict[str, any]:
        """åˆ†æä¸­æ¢å…³ç³»"""
        higher_zhongshu = higher_result.get('current_zhongshu')
        lower_zhongshu = lower_result.get('current_zhongshu')
        
        if not higher_zhongshu or not lower_zhongshu:
            return {'status': 'incomplete', 'description': 'ç¼ºå°‘ä¸­æ¢æ•°æ®'}
        
        # ä¸­æ¢åŒ…å«å…³ç³»
        is_contained = (lower_zhongshu.low >= higher_zhongshu.low and 
                       lower_zhongshu.high <= higher_zhongshu.high)
        
        # ä¸­æ¢é‡å å…³ç³»
        is_overlapping = not (lower_zhongshu.high < higher_zhongshu.low or 
                             lower_zhongshu.low > higher_zhongshu.high)
        
        # ä¸­æ¢ä½ç½®å…³ç³»
        if lower_zhongshu.center > higher_zhongshu.high:
            position = "ä¸Šæ–¹"
        elif lower_zhongshu.center < higher_zhongshu.low:
            position = "ä¸‹æ–¹"
        else:
            position = "å†…éƒ¨"
        
        return {
            'is_contained': is_contained,
            'is_overlapping': is_overlapping,
            'position': position,
            'higher_zhongshu_range': higher_zhongshu.range_ratio,
            'lower_zhongshu_range': lower_zhongshu.range_ratio
        }
    
    def _calculate_trend_consistency(self, trend_directions: Dict[TrendLevel, TrendDirection]) -> float:
        """è®¡ç®—å¤šå‘¨æœŸè¶‹åŠ¿ä¸€è‡´æ€§"""
        if len(trend_directions) < 2:
            return 0.5
        
        trends = list(trend_directions.values())
        
        # è®¡ç®—ä¸€è‡´çš„è¶‹åŠ¿å¯¹æ•°
        consistent_pairs = 0
        total_pairs = 0
        
        for i in range(len(trends)):
            for j in range(i + 1, len(trends)):
                total_pairs += 1
                if trends[i] == trends[j]:
                    consistent_pairs += 1
        
        return consistent_pairs / total_pairs if total_pairs > 0 else 0.5
    
    def _identify_dominant_trend(self, trend_directions: Dict[TrendLevel, TrendDirection], 
                               trend_strengths: Dict[TrendLevel, float]) -> TrendDirection:
        """è¯†åˆ«ä¸»å¯¼è¶‹åŠ¿"""
        if not trend_directions:
            return TrendDirection.SIDEWAYS
        
        # æŒ‰çº§åˆ«æƒé‡è®¡ç®—ï¼ˆæ–°çš„å¤šå‘¨æœŸåˆ†æï¼‰
        level_weights = {
            TrendLevel.DAILY: 3.0,      # æ—¥çº¿æƒé‡æœ€é«˜
            TrendLevel.MIN30: 2.0,      # 30åˆ†é’Ÿæ¬¡ä¹‹
            TrendLevel.MIN5: 1.0        # 5åˆ†é’Ÿæƒé‡æœ€ä½
        }
        
        # ä½¿ç”¨å­—ç¬¦ä¸²å€¼ä½œä¸ºé”®ï¼Œé¿å…æšä¸¾å®ä¾‹æ¯”è¾ƒé—®é¢˜
        trend_scores = {
            'up': 0.0,
            'down': 0.0,
            'sideways': 0.0
        }
        
        total_weight = 0.0
        
        for level, trend in trend_directions.items():
            weight = level_weights.get(level, 1.0)
            strength = trend_strengths.get(level, 0.5)
            
            # è·å–è¶‹åŠ¿çš„å­—ç¬¦ä¸²å€¼
            if hasattr(trend, 'value'):
                trend_str = trend.value
            elif isinstance(trend, str):
                trend_str = trend
            else:
                print(f"âš ï¸ æœªçŸ¥çš„è¶‹åŠ¿ç±»å‹: {type(trend)}, å€¼: {trend}, ä½¿ç”¨é»˜è®¤æ¨ªç›˜")
                trend_str = 'sideways'
            
            # ç¡®ä¿æ˜¯æœ‰æ•ˆçš„è¶‹åŠ¿å€¼
            if trend_str not in trend_scores:
                print(f"âš ï¸ æ— æ•ˆçš„è¶‹åŠ¿å€¼: {trend_str}, ä½¿ç”¨é»˜è®¤æ¨ªç›˜")
                trend_str = 'sideways'
            
            # æƒé‡ Ã— å¼ºåº¦
            score = weight * strength
            trend_scores[trend_str] += score
            total_weight += weight
        
        # å½’ä¸€åŒ–
        if total_weight > 0:
            for trend in trend_scores:
                trend_scores[trend] /= total_weight
        
        # æ‰¾åˆ°å¾—åˆ†æœ€é«˜çš„è¶‹åŠ¿å­—ç¬¦ä¸²
        dominant_trend_str = max(trend_scores, key=trend_scores.get)
        
        # è½¬æ¢å›TrendDirectionæšä¸¾
        trend_mapping = {
            'up': TrendDirection.UP,
            'down': TrendDirection.DOWN,
            'sideways': TrendDirection.SIDEWAYS
        }
        
        return trend_mapping.get(dominant_trend_str, TrendDirection.SIDEWAYS)
    
    def _identify_key_levels(self, level_results: Dict[TrendLevel, Dict]) -> Dict[str, List[float]]:
        """è¯†åˆ«å…³é”®æ”¯æ’‘é˜»åŠ›ä½"""
        support_levels = []
        resistance_levels = []
        
        for level, result in level_results.items():
            # ä»ä¸­æ¢è·å–å…³é”®ä½
            if 'zhongshu_list' in result:
                for zhongshu in result['zhongshu_list']:
                    support_levels.append(zhongshu.low)
                    resistance_levels.append(zhongshu.high)
            
            # ä»åˆ†å‹è·å–å…³é”®ä½
            if 'fenxing_tops' in result:
                for fenxing in result['fenxing_tops']:
                    resistance_levels.append(fenxing.price)
            
            if 'fenxing_bottoms' in result:
                for fenxing in result['fenxing_bottoms']:
                    support_levels.append(fenxing.price)
        
        # å»é‡å¹¶æ’åº
        support_levels = sorted(list(set(support_levels)))
        resistance_levels = sorted(list(set(resistance_levels)), reverse=True)
        
        return {
            'support': support_levels[:5],      # å–å‰5ä¸ªæ”¯æ’‘ä½
            'resistance': resistance_levels[:5] # å–å‰5ä¸ªé˜»åŠ›ä½
        }
    
    def _comprehensive_trend_assessment(self, level_results: Dict, multi_analysis: Dict, 
                                      trend_relationships: Dict) -> Dict[str, any]:
        """ç»¼åˆè¶‹åŠ¿è¯„ä¼°"""
        print("ğŸ” è¿›è¡Œç»¼åˆè¶‹åŠ¿è¯„ä¼°...")
        
        # è¶‹åŠ¿å¼ºåº¦è¯„ä¼°
        overall_strength = self._calculate_overall_trend_strength(level_results, multi_analysis)
        
        # è¶‹åŠ¿å¯é æ€§è¯„ä¼°
        reliability = self._assess_trend_reliability(trend_relationships)
        
        # æ“ä½œå»ºè®®ç”Ÿæˆ
        operation_suggestion = self._generate_operation_suggestion(
            multi_analysis, trend_relationships, overall_strength, reliability
        )
        
        # é£é™©ç­‰çº§è¯„ä¼°
        risk_level = self._assess_risk_level(overall_strength, reliability, trend_relationships)
        
        return {
            'overall_trend_strength': overall_strength,
            'trend_reliability': reliability,
            'operation_suggestion': operation_suggestion,
            'risk_level': risk_level,
            'confidence_score': (overall_strength + reliability) / 2
        }
    
    def _calculate_overall_trend_strength(self, level_results: Dict, multi_analysis: Dict) -> float:
        """è®¡ç®—æ•´ä½“è¶‹åŠ¿å¼ºåº¦"""
        strengths = []
        
        for level, result in level_results.items():
            if 'trend_strength' in result:
                strengths.append(result['trend_strength'])
        
        if not strengths:
            return 0.5
        
        # åŠ æƒå¹³å‡
        level_weights = [3.0, 2.0, 1.0]  # æ—¥çº¿ã€30åˆ†é’Ÿã€5åˆ†é’Ÿæƒé‡
        weighted_sum = sum(s * w for s, w in zip(strengths, level_weights[:len(strengths)]))
        total_weight = sum(level_weights[:len(strengths)])
        
        base_strength = weighted_sum / total_weight
        
        # è€ƒè™‘è¶‹åŠ¿ä¸€è‡´æ€§
        consistency = multi_analysis.get('trend_consistency', 0.5)
        
        return (base_strength * 0.7 + consistency * 0.3)
    
    def _assess_trend_reliability(self, trend_relationships: Dict) -> float:
        """è¯„ä¼°è¶‹åŠ¿å¯é æ€§"""
        reliability_scores = []
        
        for relationship in trend_relationships.values():
            quality = relationship.get('relationship_quality', 0.5)
            reliability_scores.append(quality)
        
        return sum(reliability_scores) / len(reliability_scores) if reliability_scores else 0.5
    
    def _evaluate_relationship_quality(self, is_consistent: bool, is_correction: bool, 
                                     strength_ratio: float) -> float:
        """è¯„ä¼°è¶‹åŠ¿å…³ç³»è´¨é‡ - ä¼˜åŒ–ç‰ˆæœ¬"""
        score = 0.1  # åŸºç¡€åˆ†æ•°é™ä½ï¼Œé¿å…è¿‡é«˜è¯„åˆ†
        
        # ä¸€è‡´æ€§åŠ åˆ†
        if is_consistent:
            score += 0.4
        
        # åˆç†çš„ä¿®æ­£å…³ç³»åŠ åˆ†ï¼ˆæ›´å®½æ¾çš„æ¡ä»¶ï¼‰
        if is_correction and 0.2 <= strength_ratio <= 0.8:
            score += 0.3
        
        # å¼ºåº¦æ¯”ä¾‹åˆç†æ€§ï¼ˆæ›´å®½æ¾çš„èŒƒå›´ï¼‰
        if 0.3 <= strength_ratio <= 2.0:
            score += 0.2
        
        # ç¡®ä¿æœ‰æ•°æ®å°±æœ‰åŸºç¡€åˆ†
        if strength_ratio > 0:
            score += 0.1
        
        return min(score, 1.0)
    
    def _generate_operation_suggestion(self, multi_analysis: Dict, trend_relationships: Dict,
                                     strength: float, reliability: float) -> str:
        """ç”Ÿæˆæ“ä½œå»ºè®®"""
        dominant_trend = multi_analysis.get('dominant_trend', TrendDirection.SIDEWAYS)
        consistency = multi_analysis.get('trend_consistency', 0.5)
        
        if strength > 0.7 and reliability > 0.7:
            if dominant_trend == TrendDirection.UP:
                return "å¼ºçƒˆå»ºè®®ä¹°å…¥ï¼šå¤šå‘¨æœŸä¸Šå‡è¶‹åŠ¿ç¡®ç«‹ï¼Œè¶‹åŠ¿å¼ºåº¦å’Œå¯é æ€§éƒ½å¾ˆé«˜"
            elif dominant_trend == TrendDirection.DOWN:
                return "å¼ºçƒˆå»ºè®®å–å‡ºï¼šå¤šå‘¨æœŸä¸‹é™è¶‹åŠ¿ç¡®ç«‹ï¼Œè¶‹åŠ¿å¼ºåº¦å’Œå¯é æ€§éƒ½å¾ˆé«˜"
            else:
                return "å»ºè®®è§‚æœ›ï¼šæ¨ªç›˜æ•´ç†ä¸­ï¼Œç­‰å¾…æ–¹å‘æ˜ç¡®"
        
        elif strength > 0.6 and reliability > 0.6:
            if dominant_trend == TrendDirection.UP:
                return "å»ºè®®ä¹°å…¥ï¼šä¸Šå‡è¶‹åŠ¿è¾ƒä¸ºæ˜ç¡®ï¼Œå¯é€‚é‡å‚ä¸"
            elif dominant_trend == TrendDirection.DOWN:
                return "å»ºè®®å–å‡ºï¼šä¸‹é™è¶‹åŠ¿è¾ƒä¸ºæ˜ç¡®ï¼Œå»ºè®®å‡ä»“"
            else:
                return "è°¨æ…è§‚æœ›ï¼šè¶‹åŠ¿ä¸å¤Ÿæ˜ç¡®ï¼Œå»ºè®®ç­‰å¾…"
        
        else:
            return "å»ºè®®è§‚æœ›ï¼šè¶‹åŠ¿ä¿¡å·ä¸å¤Ÿå¼ºçƒˆï¼Œå»ºè®®ç­‰å¾…æ›´æ˜ç¡®çš„ä¿¡å·"
    
    def _assess_risk_level(self, strength: float, reliability: float, 
                          trend_relationships: Dict) -> str:
        """è¯„ä¼°é£é™©ç­‰çº§"""
        risk_score = 1.0 - (strength + reliability) / 2
        
        # æ£€æŸ¥èƒŒç¦»æƒ…å†µ
        divergence_count = sum(1 for rel in trend_relationships.values() 
                             if rel.get('is_divergent', False))
        
        if divergence_count > 0:
            risk_score += 0.2
        
        if risk_score < 0.3:
            return "ä½é£é™©"
        elif risk_score < 0.6:
            return "ä¸­ç­‰é£é™©"
        else:
            return "é«˜é£é™©"