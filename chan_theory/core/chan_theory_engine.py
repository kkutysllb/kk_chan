#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼ è®ºåˆ†ææ ¸å¿ƒå¼•æ“
æ•´åˆæ‰€æœ‰åˆ†æå™¨ï¼Œæä¾›å®Œæ•´çš„ç¼ è®ºåˆ†æèƒ½åŠ›
ä¸“æ³¨äºåˆ†æé€»è¾‘å’Œæ•°æ®ç”Ÿæˆï¼Œè¾“å‡ºç»“æ„åŒ–çš„å¯è§†åŒ–æ•°æ®
"""

import sys
import os
from datetime import datetime, timedelta
from typing import Dict, List, Any
import pandas as pd
from dataclasses import dataclass, asdict
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
chan_theory_dir = os.path.dirname(current_dir)
project_root = os.path.dirname(os.path.dirname(os.path.dirname(chan_theory_dir)))
kk_stock_path = os.path.dirname(project_root)
kk_stock_collector_path = os.path.join(kk_stock_path, 'kk_stock_collector')

sys.path.append(project_root)
sys.path.append(kk_stock_path)
sys.path.append(kk_stock_collector_path)
sys.path.append(chan_theory_dir)

# å°è¯•ä¸åŒçš„å¯¼å…¥æ–¹å¼
try:
    from models.chan_theory_models import (
        TrendLevel, FenXingType, TrendDirection, ChanTheoryConfig
    )
    from analyzers.structure_analyzer import ChanStructureAnalyzer
    from analyzers.multi_timeframe_analyzer import MultiTimeframeAnalyzer
    from utils.data_fetcher import ChanDataFetcher
except ImportError:
    # ç»å¯¹å¯¼å…¥
    from analysis.chan_theory.models.chan_theory_models import (
        TrendLevel, FenXingType, TrendDirection, ChanTheoryConfig
    )
    from analysis.chan_theory.analyzers.structure_analyzer import ChanStructureAnalyzer
    from analysis.chan_theory.analyzers.multi_timeframe_analyzer import MultiTimeframeAnalyzer
    from analysis.chan_theory.utils.data_fetcher import ChanDataFetcher


@dataclass
class TradingSignal:
    """äº¤æ˜“ä¿¡å·"""
    signal_type: str          # ä¿¡å·ç±»å‹: 'buy' | 'sell'
    signal_level: str         # ä¿¡å·çº§åˆ«: '1buy' | '2buy' | '3buy' | '1sell' | '2sell' | '3sell'
    timeframe: TrendLevel     # ä¿¡å·æ—¶é—´çº§åˆ«
    timestamp: datetime       # ä¿¡å·æ—¶é—´
    price: float             # ä¿¡å·ä»·æ ¼
    strength: float          # ä¿¡å·å¼ºåº¦ (0-1)
    confidence: float        # ç½®ä¿¡åº¦ (0-1)
    description: str         # ä¿¡å·æè¿°
    supporting_levels: List[TrendLevel]  # æ”¯æŒçš„æ—¶é—´çº§åˆ«


@dataclass
class VisualizationData:
    """å¯è§†åŒ–æ•°æ®ç»“æ„"""
    # Kçº¿æ•°æ®
    kline_data: Dict[TrendLevel, pd.DataFrame]
    
    # ç¼ è®ºç»“æ„æ•°æ®
    fenxing_data: Dict[TrendLevel, List[Dict]]
    bi_data: Dict[TrendLevel, List[Dict]]
    xianduan_data: Dict[TrendLevel, List[Dict]]
    zhongshu_data: Dict[TrendLevel, List[Dict]]
    
    # ä¿¡å·æ•°æ®
    trading_signals: List[Dict]
    divergence_signals: List[Dict]
    
    # æ˜ å°„å…³ç³»æ•°æ®
    structure_mappings: List[Dict]
    zhongshu_inheritances: List[Dict]
    
    # æŠ€æœ¯æŒ‡æ ‡æ•°æ®
    bollinger_bands: Dict[TrendLevel, Dict]
    
    # åˆ†æç»“æœæ‘˜è¦
    analysis_summary: Dict
    
    # å›¾è¡¨é…ç½®
    chart_configs: Dict


class ChanTheoryEngine:
    """ç¼ è®ºåˆ†ææ ¸å¿ƒå¼•æ“"""
    
    def __init__(self, config: ChanTheoryConfig):
        """åˆå§‹åŒ–ç¼ è®ºå¼•æ“"""
        self.config = config
        
        # æ•°æ®è·å–å™¨
        # åˆå§‹åŒ–æ•°æ®è·å–å™¨
        from kk_stock_collector.db_handler import DBHandler
        db_handler = DBHandler()
        self.data_fetcher = ChanDataFetcher(db_handler)
        
        # å„çº§åˆ«ç»“æ„åˆ†æå™¨
        self.structure_analyzers = {}
        for level in TrendLevel:
            self.structure_analyzers[level] = ChanStructureAnalyzer(config, level)
        
        # å¤šå‘¨æœŸåˆ†æå™¨
        self.multi_analyzer = MultiTimeframeAnalyzer(config)
        
        # åˆ†æç»“æœç¼“å­˜
        self._analysis_cache = {}
        self._last_analysis_time = None
        
        print("ğŸš€ ç¼ è®ºåˆ†ææ ¸å¿ƒå¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def analyze_complete(self, symbol: str, start_date: datetime, end_date: datetime) -> Dict[str, Any]:
        """
        å®Œæ•´ç¼ è®ºåˆ†æ
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ  
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            å®Œæ•´åˆ†æç»“æœï¼ŒåŒ…å«å¯è§†åŒ–æ•°æ®
        """
        print(f"ğŸ” å¼€å§‹ {symbol} å®Œæ•´ç¼ è®ºåˆ†æ...")
        
        # 1. è·å–å¤šå‘¨æœŸæ•°æ®
        multi_data = self._fetch_multi_timeframe_data(symbol, start_date, end_date)
        
        if not any(not df.empty for df in multi_data.values()):
            return self._empty_analysis_result(symbol)
        
        # 2. æ‰§è¡Œå¤šçº§åˆ«ç»“æ„åˆ†æ
        structure_results = self._analyze_multi_level_structures(multi_data)
        
        # 3. æ‰§è¡Œæ˜ å°„å…³ç³»åˆ†æ
        mapping_results = self._analyze_structure_mappings(structure_results, multi_data)
        
        # 4. æ‰§è¡Œä¿¡å·æ£€æµ‹
        signal_results = self._detect_trading_signals(structure_results, multi_data)
        
        # 5. æ‰§è¡ŒèƒŒç¦»åˆ†æ
        divergence_results = self._analyze_divergences(structure_results, multi_data)
        
        # 6. ç”Ÿæˆå¯è§†åŒ–æ•°æ®
        visualization_data = self._generate_visualization_data(
            multi_data, structure_results, mapping_results, 
            signal_results, divergence_results
        )
        
        # 7. ç”Ÿæˆåˆ†ææ‘˜è¦
        analysis_summary = self._generate_analysis_summary(
            structure_results, mapping_results, signal_results, divergence_results
        )
        
        # 8. æ„å»ºå®Œæ•´ç»“æœ
        complete_result = {
            'symbol': symbol,
            'analysis_timeframe': f"{start_date.date()} è‡³ {end_date.date()}",
            'analysis_timestamp': datetime.now(),
            
            # æ ¸å¿ƒåˆ†æç»“æœ
            'structure_results': structure_results,
            'mapping_results': mapping_results,
            'signal_results': signal_results,
            'divergence_results': divergence_results,
            
            # å¯è§†åŒ–æ•°æ®
            'visualization_data': visualization_data,
            
            # åˆ†ææ‘˜è¦
            'analysis_summary': analysis_summary,
            
            # æ“ä½œå»ºè®®
            'operation_advice': self._generate_operation_advice(signal_results, analysis_summary)
        }
        
        print("âœ… å®Œæ•´ç¼ è®ºåˆ†æå®Œæˆ")
        return complete_result
    
    def _fetch_multi_timeframe_data(self, symbol: str, start_date: datetime, end_date: datetime) -> Dict[TrendLevel, pd.DataFrame]:
        """è·å–å¤šå‘¨æœŸæ•°æ®"""
        print("ğŸ“Š è·å–å¤šå‘¨æœŸKçº¿æ•°æ®...")
        
        multi_data = {}
        
        for level in TrendLevel:
            try:
                data = self.data_fetcher.get_kline_data(symbol, level, start_date, end_date)
                multi_data[level] = data
                
                if not data.empty:
                    print(f"âœ… {level.value}: {len(data)} æ¡æ•°æ®")
                else:
                    print(f"âš ï¸ {level.value}: æ— æ•°æ®")
                    
            except Exception as e:
                print(f"âŒ {level.value} æ•°æ®è·å–å¤±è´¥: {e}")
                multi_data[level] = pd.DataFrame()
        
        return multi_data
    
    def _analyze_multi_level_structures(self, multi_data: Dict[TrendLevel, pd.DataFrame]) -> Dict[str, Any]:
        """å¤šçº§åˆ«ç»“æ„åˆ†æ"""
        print("ğŸ” æ‰§è¡Œå¤šçº§åˆ«ç»“æ„åˆ†æ...")
        
        level_results = {}
        
        for level, data in multi_data.items():
            if data.empty:
                continue
                
            print(f"ğŸ“Š åˆ†æ {level.value} çº§åˆ«ç»“æ„...")
            analyzer = self.structure_analyzers[level]
            
            try:
                result = analyzer.analyze_single_timeframe(data)
                level_results[level] = result
                
                # ç»Ÿè®¡ç»“æ„æ•°é‡
                fenxing_count = len(result.get('fenxing_tops', [])) + len(result.get('fenxing_bottoms', []))
                bi_count = len(result.get('bi_list', []))
                xd_count = len(result.get('xd_list', []))
                zs_count = len(result.get('zhongshu_list', []))
                
                print(f"  åˆ†å‹: {fenxing_count}, ç¬”: {bi_count}, çº¿æ®µ: {xd_count}, ä¸­æ¢: {zs_count}")
                
            except Exception as e:
                print(f"âŒ {level.value} ç»“æ„åˆ†æå¤±è´¥: {e}")
                level_results[level] = self._empty_level_result()
        
        return {
            'level_results': level_results,
            'multi_timeframe_analysis': self.multi_analyzer.analyze_multi_timeframe_trend(multi_data)
        }
    
    def _analyze_structure_mappings(self, structure_results: Dict, multi_data: Dict) -> Dict[str, Any]:
        """ç»“æ„æ˜ å°„å…³ç³»åˆ†æ"""
        print("ğŸ” åˆ†æç»“æ„æ˜ å°„å…³ç³»...")
        
        level_results = structure_results.get('level_results', {})
        
        try:
            # ä½¿ç”¨ç»“æ„æ˜ å°„åˆ†æå™¨
            from analyzers.structure_mapping_analysis import StructureMappingAnalyzer
            mapping_analyzer = StructureMappingAnalyzer()
            mapping_analysis = mapping_analyzer.analyze_structure_mappings(self.config.symbol)
            
            return {
                'structure_mappings': mapping_analysis.get('mapping_relationships', {}),
                'zhongshu_inheritances': mapping_analysis.get('zhongshu_inheritance', {}),
                'resonance_analysis': mapping_analysis.get('resonance_analysis', {}),
                'mapping_quality': mapping_analysis.get('mapping_relationships', {}).get('overall_quality', 0.0)
            }
            
        except Exception as e:
            print(f"âŒ æ˜ å°„å…³ç³»åˆ†æå¤±è´¥: {e}")
            return {
                'structure_mappings': {},
                'zhongshu_inheritances': {},
                'resonance_analysis': {},
                'mapping_quality': 0.0
            }
    
    def _detect_trading_signals(self, structure_results: Dict, multi_data: Dict) -> Dict[str, Any]:
        """äº¤æ˜“ä¿¡å·æ£€æµ‹"""
        print("ğŸ” æ£€æµ‹äº¤æ˜“ä¿¡å·...")
        
        all_signals = []
        level_results = structure_results.get('level_results', {})
        
        for level, result in level_results.items():
            if not result:
                continue
                
            # æ£€æµ‹ä¹°å–ç‚¹
            buy_signals = self._detect_buy_signals(level, result, multi_data.get(level))
            sell_signals = self._detect_sell_signals(level, result, multi_data.get(level))
            
            all_signals.extend(buy_signals)
            all_signals.extend(sell_signals)
        
        # å¤šçº§åˆ«ä¿¡å·éªŒè¯
        validated_signals = self._validate_multi_level_signals(all_signals)
        
        # æŒ‰æ—¶é—´æ’åº
        validated_signals.sort(key=lambda x: x['timestamp'])
        
        return {
            'all_signals': all_signals,
            'validated_signals': validated_signals,
            'signal_summary': self._summarize_signals(validated_signals),
            'current_recommendation': self._get_current_recommendation(validated_signals)
        }
    
    def _detect_buy_signals(self, level: TrendLevel, structure_result: Dict, data: pd.DataFrame) -> List[Dict]:
        """æ£€æµ‹ä¹°å…¥ä¿¡å·"""
        buy_signals = []
        
        if data is None or data.empty:
            return buy_signals
        
        # 1ç±»ä¹°ç‚¹ï¼šè¶‹åŠ¿èƒŒé©°åçš„åè½¬
        first_buy_points = self._detect_first_buy_points(level, structure_result, data)
        buy_signals.extend(first_buy_points)
        
        # 2ç±»ä¹°ç‚¹ï¼šä¸­æ¢éœ‡è¡åçš„çªç ´
        second_buy_points = self._detect_second_buy_points(level, structure_result, data)
        buy_signals.extend(second_buy_points)
        
        # 3ç±»ä¹°ç‚¹ï¼šä¸­æ¢å†…çš„ä½ä½
        third_buy_points = self._detect_third_buy_points(level, structure_result, data)
        buy_signals.extend(third_buy_points)
        
        return buy_signals
    
    def _detect_sell_signals(self, level: TrendLevel, structure_result: Dict, data: pd.DataFrame) -> List[Dict]:
        """æ£€æµ‹å–å‡ºä¿¡å·"""
        sell_signals = []
        
        if data is None or data.empty:
            return sell_signals
        
        # 1ç±»å–ç‚¹ï¼šè¶‹åŠ¿èƒŒé©°åçš„åè½¬
        first_sell_points = self._detect_first_sell_points(level, structure_result, data)
        sell_signals.extend(first_sell_points)
        
        # 2ç±»å–ç‚¹ï¼šä¸­æ¢éœ‡è¡åçš„çªç ´
        second_sell_points = self._detect_second_sell_points(level, structure_result, data)
        sell_signals.extend(second_sell_points)
        
        # 3ç±»å–ç‚¹ï¼šä¸­æ¢å†…çš„é«˜ä½
        third_sell_points = self._detect_third_sell_points(level, structure_result, data)
        sell_signals.extend(third_sell_points)
        
        return sell_signals
    
    def _detect_first_buy_points(self, level: TrendLevel, structure_result: Dict, data: pd.DataFrame) -> List[Dict]:
        """æ£€æµ‹ä¸€ç±»ä¹°ç‚¹"""
        signals = []
        
        # æŸ¥æ‰¾ä¸‹è·Œè¶‹åŠ¿çš„èƒŒé©°ç‚¹
        zhongshu_list = structure_result.get('zhongshu_list', [])
        bi_list = structure_result.get('bi_list', [])
        
        for i, zs in enumerate(zhongshu_list):
            if hasattr(zs, 'end_time'):
                # æŸ¥æ‰¾ä¸­æ¢åçš„ä¸‹è·Œçº¿æ®µæ˜¯å¦èƒŒé©°
                post_zs_bis = [bi for bi in bi_list if hasattr(bi, 'start_time') and bi.start_time > zs.end_time]
                
                if len(post_zs_bis) >= 2:
                    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨èƒŒé©°
                    if self._check_divergence(post_zs_bis[-2:], 'down'):
                        signal = {
                            'signal_type': 'buy',
                            'signal_level': '1buy',
                            'timeframe': level,
                            'timestamp': post_zs_bis[-1].end_time if hasattr(post_zs_bis[-1], 'end_time') else datetime.now(),
                            'price': post_zs_bis[-1].end_price if hasattr(post_zs_bis[-1], 'end_price') else 0.0,
                            'strength': 0.8,
                            'confidence': 0.7,
                            'description': f'{level.value}çº§åˆ«ä¸€ç±»ä¹°ç‚¹ï¼šä¸‹è·ŒèƒŒé©°',
                            'supporting_data': {
                                'zhongshu': asdict(zs) if hasattr(zs, '__dict__') else zs,
                                'divergence_bis': [asdict(bi) if hasattr(bi, '__dict__') else bi for bi in post_zs_bis[-2:]]
                            }
                        }
                        signals.append(signal)
        
        return signals
    
    def _detect_second_buy_points(self, level: TrendLevel, structure_result: Dict, data: pd.DataFrame) -> List[Dict]:
        """æ£€æµ‹äºŒç±»ä¹°ç‚¹"""
        signals = []
        
        zhongshu_list = structure_result.get('zhongshu_list', [])
        
        for zs in zhongshu_list:
            if hasattr(zs, 'low') and hasattr(zs, 'end_time'):
                # æŸ¥æ‰¾å‘ä¸‹ç¦»å¼€ä¸­æ¢åé‡æ–°å‘ä¸Šçš„ç‚¹
                recent_data = data[data.index > zs.end_time] if hasattr(zs, 'end_time') else data.tail(20)
                
                if not recent_data.empty:
                    # æŸ¥æ‰¾æœ€ä½ç‚¹åçš„åè½¬
                    min_idx = recent_data['low'].idxmin()
                    min_price = recent_data.loc[min_idx, 'low']
                    
                    # æ£€æŸ¥æ˜¯å¦æ¥è¿‘ä¸­æ¢ä¸‹æ²¿
                    if abs(min_price - zs.low) / zs.low < 0.02:  # 2%èŒƒå›´å†…
                        signal = {
                            'signal_type': 'buy',
                            'signal_level': '2buy',
                            'timeframe': level,
                            'timestamp': min_idx,
                            'price': min_price,
                            'strength': 0.6,
                            'confidence': 0.6,
                            'description': f'{level.value}çº§åˆ«äºŒç±»ä¹°ç‚¹ï¼šä¸­æ¢ä¸‹æ²¿å›è¸©',
                            'supporting_data': {
                                'zhongshu': asdict(zs) if hasattr(zs, '__dict__') else zs,
                                'retest_price': min_price
                            }
                        }
                        signals.append(signal)
        
        return signals
    
    def _detect_third_buy_points(self, level: TrendLevel, structure_result: Dict, data: pd.DataFrame) -> List[Dict]:
        """æ£€æµ‹ä¸‰ç±»ä¹°ç‚¹"""
        signals = []
        
        zhongshu_list = structure_result.get('zhongshu_list', [])
        current_time = data.index[-1] if not data.empty else datetime.now()
        
        for zs in zhongshu_list:
            if hasattr(zs, 'low') and hasattr(zs, 'high') and hasattr(zs, 'end_time'):
                # æ£€æŸ¥å½“å‰ä»·æ ¼æ˜¯å¦åœ¨ä¸­æ¢å†…
                if zs.end_time > current_time - timedelta(days=30):  # æœ€è¿‘çš„ä¸­æ¢
                    current_price = data.iloc[-1]['close'] if not data.empty else 0
                    
                    if zs.low <= current_price <= zs.high:
                        # ä¸­æ¢å†…çš„ä½ä½ä¹°ç‚¹
                        zs_range = zs.high - zs.low
                        position_in_zs = (current_price - zs.low) / zs_range
                        
                        if position_in_zs < 0.3:  # åœ¨ä¸­æ¢ä¸‹1/3ä½ç½®
                            signal = {
                                'signal_type': 'buy',
                                'signal_level': '3buy',
                                'timeframe': level,
                                'timestamp': current_time,
                                'price': current_price,
                                'strength': 0.4,
                                'confidence': 0.5,
                                'description': f'{level.value}çº§åˆ«ä¸‰ç±»ä¹°ç‚¹ï¼šä¸­æ¢å†…ä½ä½',
                                'supporting_data': {
                                    'zhongshu': asdict(zs) if hasattr(zs, '__dict__') else zs,
                                    'position_ratio': position_in_zs
                                }
                            }
                            signals.append(signal)
        
        return signals
    
    def _detect_first_sell_points(self, level: TrendLevel, structure_result: Dict, data: pd.DataFrame) -> List[Dict]:
        """æ£€æµ‹ä¸€ç±»å–ç‚¹"""
        signals = []
        
        zhongshu_list = structure_result.get('zhongshu_list', [])
        bi_list = structure_result.get('bi_list', [])
        
        for i, zs in enumerate(zhongshu_list):
            if hasattr(zs, 'end_time'):
                # æŸ¥æ‰¾ä¸­æ¢åçš„ä¸Šæ¶¨çº¿æ®µæ˜¯å¦èƒŒé©°
                post_zs_bis = [bi for bi in bi_list if hasattr(bi, 'start_time') and bi.start_time > zs.end_time]
                
                if len(post_zs_bis) >= 2:
                    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨èƒŒé©°
                    if self._check_divergence(post_zs_bis[-2:], 'up'):
                        signal = {
                            'signal_type': 'sell',
                            'signal_level': '1sell',
                            'timeframe': level,
                            'timestamp': post_zs_bis[-1].end_time if hasattr(post_zs_bis[-1], 'end_time') else datetime.now(),
                            'price': post_zs_bis[-1].end_price if hasattr(post_zs_bis[-1], 'end_price') else 0.0,
                            'strength': 0.8,
                            'confidence': 0.7,
                            'description': f'{level.value}çº§åˆ«ä¸€ç±»å–ç‚¹ï¼šä¸Šæ¶¨èƒŒé©°',
                            'supporting_data': {
                                'zhongshu': asdict(zs) if hasattr(zs, '__dict__') else zs,
                                'divergence_bis': [asdict(bi) if hasattr(bi, '__dict__') else bi for bi in post_zs_bis[-2:]]
                            }
                        }
                        signals.append(signal)
        
        return signals
    
    def _detect_second_sell_points(self, level: TrendLevel, structure_result: Dict, data: pd.DataFrame) -> List[Dict]:
        """æ£€æµ‹äºŒç±»å–ç‚¹"""
        signals = []
        
        zhongshu_list = structure_result.get('zhongshu_list', [])
        
        for zs in zhongshu_list:
            if hasattr(zs, 'high') and hasattr(zs, 'end_time'):
                # æŸ¥æ‰¾å‘ä¸Šç¦»å¼€ä¸­æ¢åé‡æ–°å‘ä¸‹çš„ç‚¹
                recent_data = data[data.index > zs.end_time] if hasattr(zs, 'end_time') else data.tail(20)
                
                if not recent_data.empty:
                    # æŸ¥æ‰¾æœ€é«˜ç‚¹åçš„åè½¬
                    max_idx = recent_data['high'].idxmax()
                    max_price = recent_data.loc[max_idx, 'high']
                    
                    # æ£€æŸ¥æ˜¯å¦æ¥è¿‘ä¸­æ¢ä¸Šæ²¿
                    if abs(max_price - zs.high) / zs.high < 0.02:  # 2%èŒƒå›´å†…
                        signal = {
                            'signal_type': 'sell',
                            'signal_level': '2sell',
                            'timeframe': level,
                            'timestamp': max_idx,
                            'price': max_price,
                            'strength': 0.6,
                            'confidence': 0.6,
                            'description': f'{level.value}çº§åˆ«äºŒç±»å–ç‚¹ï¼šä¸­æ¢ä¸Šæ²¿å›è¸©',
                            'supporting_data': {
                                'zhongshu': asdict(zs) if hasattr(zs, '__dict__') else zs,
                                'retest_price': max_price
                            }
                        }
                        signals.append(signal)
        
        return signals
    
    def _detect_third_sell_points(self, level: TrendLevel, structure_result: Dict, data: pd.DataFrame) -> List[Dict]:
        """æ£€æµ‹ä¸‰ç±»å–ç‚¹"""
        signals = []
        
        zhongshu_list = structure_result.get('zhongshu_list', [])
        current_time = data.index[-1] if not data.empty else datetime.now()
        
        for zs in zhongshu_list:
            if hasattr(zs, 'low') and hasattr(zs, 'high') and hasattr(zs, 'end_time'):
                # æ£€æŸ¥å½“å‰ä»·æ ¼æ˜¯å¦åœ¨ä¸­æ¢å†…
                if zs.end_time > current_time - timedelta(days=30):  # æœ€è¿‘çš„ä¸­æ¢
                    current_price = data.iloc[-1]['close'] if not data.empty else 0
                    
                    if zs.low <= current_price <= zs.high:
                        # ä¸­æ¢å†…çš„é«˜ä½å–ç‚¹
                        zs_range = zs.high - zs.low
                        position_in_zs = (current_price - zs.low) / zs_range
                        
                        if position_in_zs > 0.7:  # åœ¨ä¸­æ¢ä¸Š1/3ä½ç½®
                            signal = {
                                'signal_type': 'sell',
                                'signal_level': '3sell',
                                'timeframe': level,
                                'timestamp': current_time,
                                'price': current_price,
                                'strength': 0.4,
                                'confidence': 0.5,
                                'description': f'{level.value}çº§åˆ«ä¸‰ç±»å–ç‚¹ï¼šä¸­æ¢å†…é«˜ä½',
                                'supporting_data': {
                                    'zhongshu': asdict(zs) if hasattr(zs, '__dict__') else zs,
                                    'position_ratio': position_in_zs
                                }
                            }
                            signals.append(signal)
        
        return signals
    
    def _check_divergence(self, bis: List, direction: str) -> bool:
        """æ£€æŸ¥èƒŒé©°"""
        if len(bis) < 2:
            return False
        
        bi1, bi2 = bis[-2], bis[-1]
        
        # ç®€åŒ–çš„èƒŒé©°æ£€æŸ¥ï¼šæ¯”è¾ƒä»·æ ¼å¹…åº¦å’ŒåŠ›åº¦
        if direction == 'down':
            # ä¸‹è·ŒèƒŒé©°ï¼šä»·æ ¼æ–°ä½ä½†åŠ›åº¦å‡å¼±
            price_new_low = getattr(bi2, 'end_price', 0) < getattr(bi1, 'end_price', 0)
            amplitude_weakened = getattr(bi2, 'amplitude', 0) < getattr(bi1, 'amplitude', 0)
            return price_new_low and amplitude_weakened
        else:
            # ä¸Šæ¶¨èƒŒé©°ï¼šä»·æ ¼æ–°é«˜ä½†åŠ›åº¦å‡å¼±
            price_new_high = getattr(bi2, 'end_price', 0) > getattr(bi1, 'end_price', 0)
            amplitude_weakened = getattr(bi2, 'amplitude', 0) < getattr(bi1, 'amplitude', 0)
            return price_new_high and amplitude_weakened
    
    def _validate_multi_level_signals(self, all_signals: List[Dict]) -> List[Dict]:
        """å¤šçº§åˆ«ä¿¡å·éªŒè¯"""
        validated_signals = []
        
        # æŒ‰æ—¶é—´åˆ†ç»„
        signal_groups = {}
        for signal in all_signals:
            time_key = signal['timestamp'].strftime('%Y-%m-%d')
            if time_key not in signal_groups:
                signal_groups[time_key] = []
            signal_groups[time_key].append(signal)
        
        # éªŒè¯æ¯ç»„ä¿¡å·
        for time_key, signals in signal_groups.items():
            if len(signals) > 1:
                # å¤šçº§åˆ«å…±æŒ¯ä¿¡å·
                buy_signals = [s for s in signals if s['signal_type'] == 'buy']
                sell_signals = [s for s in signals if s['signal_type'] == 'sell']
                
                if len(buy_signals) > 1:
                    # ä¹°å…¥å…±æŒ¯
                    main_signal = max(buy_signals, key=lambda x: x['strength'])
                    main_signal['confidence'] += 0.2  # æé«˜ç½®ä¿¡åº¦
                    main_signal['description'] += f" (å¤šçº§åˆ«å…±æŒ¯: {len(buy_signals)}ä¸ªçº§åˆ«)"
                    main_signal['supporting_levels'] = [s['timeframe'] for s in buy_signals]
                    validated_signals.append(main_signal)
                
                if len(sell_signals) > 1:
                    # å–å‡ºå…±æŒ¯
                    main_signal = max(sell_signals, key=lambda x: x['strength'])
                    main_signal['confidence'] += 0.2  # æé«˜ç½®ä¿¡åº¦
                    main_signal['description'] += f" (å¤šçº§åˆ«å…±æŒ¯: {len(sell_signals)}ä¸ªçº§åˆ«)"
                    main_signal['supporting_levels'] = [s['timeframe'] for s in sell_signals]
                    validated_signals.append(main_signal)
            else:
                # å•çº§åˆ«ä¿¡å·
                validated_signals.extend(signals)
        
        return validated_signals
    
    def _analyze_divergences(self, structure_results: Dict, multi_data: Dict) -> Dict[str, Any]:
        """èƒŒç¦»åˆ†æ"""
        print("ğŸ” åˆ†æèƒŒç¦»ä¿¡å·...")
        
        divergence_signals = []
        level_results = structure_results.get('level_results', {})
        
        # å„çº§åˆ«èƒŒç¦»æ£€æµ‹
        for level, result in level_results.items():
            if not result:
                continue
            
            # æ£€æµ‹é¡¶èƒŒç¦»
            top_divergences = self._detect_top_divergences(level, result, multi_data.get(level))
            divergence_signals.extend(top_divergences)
            
            # æ£€æµ‹åº•èƒŒç¦»
            bottom_divergences = self._detect_bottom_divergences(level, result, multi_data.get(level))
            divergence_signals.extend(bottom_divergences)
        
        return {
            'divergence_signals': divergence_signals,
            'divergence_summary': self._summarize_divergences(divergence_signals)
        }
    
    def _detect_top_divergences(self, level: TrendLevel, structure_result: Dict, data: pd.DataFrame) -> List[Dict]:
        """æ£€æµ‹é¡¶èƒŒç¦»"""
        divergences = []
        
        if data is None or data.empty:
            return divergences
        
        fenxing_tops = structure_result.get('fenxing_tops', [])
        
        if len(fenxing_tops) >= 2:
            for i in range(1, len(fenxing_tops)):
                current_top = fenxing_tops[i]
                previous_top = fenxing_tops[i-1]
                
                # æ£€æŸ¥ä»·æ ¼å’ŒæŒ‡æ ‡çš„èƒŒç¦»
                if hasattr(current_top, 'price') and hasattr(previous_top, 'price'):
                    price_higher = current_top.price > previous_top.price
                    
                    # ç®€åŒ–çš„åŠ›åº¦æ¯”è¾ƒï¼ˆå®é™…åº”è¯¥ç”¨MACDç­‰æŒ‡æ ‡ï¼‰
                    current_strength = getattr(current_top, 'strength', 0)
                    previous_strength = getattr(previous_top, 'strength', 0)
                    strength_weaker = current_strength < previous_strength
                    
                    if price_higher and strength_weaker:
                        divergence = {
                            'type': 'top_divergence',
                            'level': level,
                            'timestamp': getattr(current_top, 'timestamp', datetime.now()),
                            'price': current_top.price,
                            'strength': 0.7,
                            'description': f'{level.value}çº§åˆ«é¡¶èƒŒç¦»',
                            'supporting_data': {
                                'current_top': asdict(current_top) if hasattr(current_top, '__dict__') else current_top,
                                'previous_top': asdict(previous_top) if hasattr(previous_top, '__dict__') else previous_top
                            }
                        }
                        divergences.append(divergence)
        
        return divergences
    
    def _detect_bottom_divergences(self, level: TrendLevel, structure_result: Dict, data: pd.DataFrame) -> List[Dict]:
        """æ£€æµ‹åº•èƒŒç¦»"""
        divergences = []
        
        if data is None or data.empty:
            return divergences
        
        fenxing_bottoms = structure_result.get('fenxing_bottoms', [])
        
        if len(fenxing_bottoms) >= 2:
            for i in range(1, len(fenxing_bottoms)):
                current_bottom = fenxing_bottoms[i]
                previous_bottom = fenxing_bottoms[i-1]
                
                # æ£€æŸ¥ä»·æ ¼å’ŒæŒ‡æ ‡çš„èƒŒç¦»
                if hasattr(current_bottom, 'price') and hasattr(previous_bottom, 'price'):
                    price_lower = current_bottom.price < previous_bottom.price
                    
                    # ç®€åŒ–çš„åŠ›åº¦æ¯”è¾ƒ
                    current_strength = getattr(current_bottom, 'strength', 0)
                    previous_strength = getattr(previous_bottom, 'strength', 0)
                    strength_weaker = current_strength < previous_strength
                    
                    if price_lower and strength_weaker:
                        divergence = {
                            'type': 'bottom_divergence',
                            'level': level,
                            'timestamp': getattr(current_bottom, 'timestamp', datetime.now()),
                            'price': current_bottom.price,
                            'strength': 0.7,
                            'description': f'{level.value}çº§åˆ«åº•èƒŒç¦»',
                            'supporting_data': {
                                'current_bottom': asdict(current_bottom) if hasattr(current_bottom, '__dict__') else current_bottom,
                                'previous_bottom': asdict(previous_bottom) if hasattr(previous_bottom, '__dict__') else previous_bottom
                            }
                        }
                        divergences.append(divergence)
        
        return divergences
    
    def _generate_visualization_data(self, multi_data: Dict, structure_results: Dict, 
                                   mapping_results: Dict, signal_results: Dict, 
                                   divergence_results: Dict) -> VisualizationData:
        """ç”Ÿæˆå¯è§†åŒ–æ•°æ®ç»“æ„"""
        print("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–æ•°æ®...")
        
        level_results = structure_results.get('level_results', {})
        
        # è½¬æ¢ç»“æ„æ•°æ®ä¸ºå¯è§†åŒ–æ ¼å¼
        fenxing_data = {}
        bi_data = {}
        xianduan_data = {}
        zhongshu_data = {}
        bollinger_data = {}
        
        for level, result in level_results.items():
            # åˆ†å‹æ•°æ®
            fenxing_data[level] = self._format_fenxing_for_viz(result.get('fenxing_tops', []), result.get('fenxing_bottoms', []))
            
            # ç¬”æ•°æ®
            bi_data[level] = self._format_bi_for_viz(result.get('bi_list', []))
            
            # çº¿æ®µæ•°æ®
            xianduan_data[level] = self._format_xianduan_for_viz(result.get('xd_list', []))
            
            # ä¸­æ¢æ•°æ®
            zhongshu_data[level] = self._format_zhongshu_for_viz(result.get('zhongshu_list', []))
            
            # å¸ƒæ—å¸¦æ•°æ®
            bollinger_data[level] = self._format_bollinger_for_viz(result.get('bollinger_bands'))
        
        # ä¿¡å·æ•°æ®
        trading_signals = self._format_signals_for_viz(signal_results.get('validated_signals', []))
        divergence_signals = self._format_divergences_for_viz(divergence_results.get('divergence_signals', []))
        
        # æ˜ å°„å…³ç³»æ•°æ®
        structure_mappings = self._format_mappings_for_viz(mapping_results.get('structure_mappings', {}))
        zhongshu_inheritances = self._format_inheritances_for_viz(mapping_results.get('zhongshu_inheritances', {}))
        
        # åˆ†ææ‘˜è¦
        analysis_summary = self._format_summary_for_viz(structure_results, signal_results, divergence_results)
        
        # å›¾è¡¨é…ç½®
        chart_configs = self._generate_chart_configs(multi_data)
        
        return VisualizationData(
            kline_data=multi_data,
            fenxing_data=fenxing_data,
            bi_data=bi_data,
            xianduan_data=xianduan_data,
            zhongshu_data=zhongshu_data,
            trading_signals=trading_signals,
            divergence_signals=divergence_signals,
            structure_mappings=structure_mappings,
            zhongshu_inheritances=zhongshu_inheritances,
            bollinger_bands=bollinger_data,
            analysis_summary=analysis_summary,
            chart_configs=chart_configs
        )
    
    def _format_fenxing_for_viz(self, tops: List, bottoms: List) -> List[Dict]:
        """æ ¼å¼åŒ–åˆ†å‹æ•°æ®ä¾›å¯è§†åŒ–ä½¿ç”¨"""
        fenxing_viz = []
        
        for top in tops:
            fenxing_viz.append({
                'type': 'top',
                'timestamp': getattr(top, 'timestamp', datetime.now()),
                'price': getattr(top, 'price', 0),
                'strength': getattr(top, 'strength', 0),
                'confirmed': getattr(top, 'confirmed', False)
            })
        
        for bottom in bottoms:
            fenxing_viz.append({
                'type': 'bottom',
                'timestamp': getattr(bottom, 'timestamp', datetime.now()),
                'price': getattr(bottom, 'price', 0),
                'strength': getattr(bottom, 'strength', 0),
                'confirmed': getattr(bottom, 'confirmed', False)
            })
        
        # æŒ‰æ—¶é—´æ’åº
        fenxing_viz.sort(key=lambda x: x['timestamp'])
        return fenxing_viz
    
    def _format_bi_for_viz(self, bi_list: List) -> List[Dict]:
        """æ ¼å¼åŒ–ç¬”æ•°æ®ä¾›å¯è§†åŒ–ä½¿ç”¨"""
        bi_viz = []
        
        for bi in bi_list:
            bi_viz.append({
                'start_time': getattr(bi, 'start_time', datetime.now()),
                'end_time': getattr(bi, 'end_time', datetime.now()),
                'start_price': getattr(bi, 'start_price', 0),
                'end_price': getattr(bi, 'end_price', 0),
                'direction': getattr(bi, 'direction', TrendDirection.SIDEWAYS).value if hasattr(getattr(bi, 'direction', None), 'value') else str(getattr(bi, 'direction', 'unknown')),
                'amplitude': getattr(bi, 'amplitude', 0),
                'length': getattr(bi, 'length', 0)
            })
        
        return bi_viz
    
    def _format_xianduan_for_viz(self, xd_list: List) -> List[Dict]:
        """æ ¼å¼åŒ–çº¿æ®µæ•°æ®ä¾›å¯è§†åŒ–ä½¿ç”¨"""
        xd_viz = []
        
        for xd in xd_list:
            xd_viz.append({
                'start_time': getattr(xd, 'start_time', datetime.now()),
                'end_time': getattr(xd, 'end_time', datetime.now()),
                'start_price': getattr(xd, 'start_price', 0),
                'end_price': getattr(xd, 'end_price', 0),
                'direction': getattr(xd, 'direction', TrendDirection.SIDEWAYS).value if hasattr(getattr(xd, 'direction', None), 'value') else str(getattr(xd, 'direction', 'unknown')),
                'amplitude': getattr(xd, 'amplitude', 0),
                'bi_count': len(getattr(xd, 'bi_list', []))
            })
        
        return xd_viz
    
    def _format_zhongshu_for_viz(self, zs_list: List) -> List[Dict]:
        """æ ¼å¼åŒ–ä¸­æ¢æ•°æ®ä¾›å¯è§†åŒ–ä½¿ç”¨"""
        zs_viz = []
        
        for zs in zs_list:
            zs_viz.append({
                'start_time': getattr(zs, 'start_time', datetime.now()),
                'end_time': getattr(zs, 'end_time', datetime.now()),
                'high': getattr(zs, 'high', 0),
                'low': getattr(zs, 'low', 0),
                'center': getattr(zs, 'center', 0),
                'range_ratio': getattr(zs, 'range_ratio', 0),
                'duration_days': getattr(zs, 'duration_days', 0),
                'extend_count': getattr(zs, 'extend_count', 0)
            })
        
        return zs_viz
    
    def _format_bollinger_for_viz(self, bollinger_bands) -> Dict:
        """æ ¼å¼åŒ–å¸ƒæ—å¸¦æ•°æ®ä¾›å¯è§†åŒ–ä½¿ç”¨"""
        if not bollinger_bands:
            return {}
        
        return {
            'upper': bollinger_bands.upper.to_dict() if hasattr(bollinger_bands, 'upper') else {},
            'middle': bollinger_bands.middle.to_dict() if hasattr(bollinger_bands, 'middle') else {},
            'lower': bollinger_bands.lower.to_dict() if hasattr(bollinger_bands, 'lower') else {}
        }
    
    def _format_signals_for_viz(self, signals: List[Dict]) -> List[Dict]:
        """æ ¼å¼åŒ–ä¿¡å·æ•°æ®ä¾›å¯è§†åŒ–ä½¿ç”¨"""
        return [{
            'type': signal['signal_type'],
            'level': signal['signal_level'],
            'timeframe': signal['timeframe'].value,
            'timestamp': signal['timestamp'],
            'price': signal['price'],
            'strength': signal['strength'],
            'confidence': signal['confidence'],
            'description': signal['description']
        } for signal in signals]
    
    def _format_divergences_for_viz(self, divergences: List[Dict]) -> List[Dict]:
        """æ ¼å¼åŒ–èƒŒç¦»æ•°æ®ä¾›å¯è§†åŒ–ä½¿ç”¨"""
        return [{
            'type': div['type'],
            'level': div['level'].value,
            'timestamp': div['timestamp'],
            'price': div['price'],
            'strength': div['strength'],
            'description': div['description']
        } for div in divergences]
    
    def _format_mappings_for_viz(self, mappings: Dict) -> List[Dict]:
        """æ ¼å¼åŒ–æ˜ å°„å…³ç³»æ•°æ®ä¾›å¯è§†åŒ–ä½¿ç”¨"""
        # ç®€åŒ–å®ç°
        return []
    
    def _format_inheritances_for_viz(self, inheritances: Dict) -> List[Dict]:
        """æ ¼å¼åŒ–ä¸­æ¢ç»§æ‰¿æ•°æ®ä¾›å¯è§†åŒ–ä½¿ç”¨"""
        # ç®€åŒ–å®ç°
        return []
    
    def _format_summary_for_viz(self, structure_results: Dict, signal_results: Dict, divergence_results: Dict) -> Dict:
        """æ ¼å¼åŒ–åˆ†ææ‘˜è¦ä¾›å¯è§†åŒ–ä½¿ç”¨"""
        level_results = structure_results.get('level_results', {})
        
        summary = {
            'total_levels': len(level_results),
            'structure_counts': {},
            'signal_counts': {
                'total_signals': len(signal_results.get('validated_signals', [])),
                'buy_signals': len([s for s in signal_results.get('validated_signals', []) if s['signal_type'] == 'buy']),
                'sell_signals': len([s for s in signal_results.get('validated_signals', []) if s['signal_type'] == 'sell'])
            },
            'divergence_counts': {
                'total_divergences': len(divergence_results.get('divergence_signals', [])),
                'top_divergences': len([d for d in divergence_results.get('divergence_signals', []) if d['type'] == 'top_divergence']),
                'bottom_divergences': len([d for d in divergence_results.get('divergence_signals', []) if d['type'] == 'bottom_divergence'])
            }
        }
        
        # å„çº§åˆ«ç»“æ„ç»Ÿè®¡
        for level, result in level_results.items():
            summary['structure_counts'][level.value] = {
                'fenxing': len(result.get('fenxing_tops', [])) + len(result.get('fenxing_bottoms', [])),
                'bi': len(result.get('bi_list', [])),
                'xianduan': len(result.get('xd_list', [])),
                'zhongshu': len(result.get('zhongshu_list', []))
            }
        
        return summary
    
    def _generate_chart_configs(self, multi_data: Dict) -> Dict:
        """ç”Ÿæˆå›¾è¡¨é…ç½®"""
        configs = {
            'timeframes': [level.value for level in multi_data.keys() if not multi_data[level].empty],
            'date_range': {},
            'price_range': {},
            'colors': {
                'up_candle': '#FF6B6B',
                'down_candle': '#4ECDC4',
                'fenxing_top': '#FF4444',
                'fenxing_bottom': '#44FF44',
                'bi': '#FFD93D',
                'xianduan': '#6BCF7F',
                'zhongshu': '#A8E6CF',
                'buy_signal': '#00FF00',
                'sell_signal': '#FF0000'
            }
        }
        
        # è®¡ç®—å„çº§åˆ«çš„æ—¶é—´å’Œä»·æ ¼èŒƒå›´
        for level, data in multi_data.items():
            if not data.empty:
                configs['date_range'][level.value] = {
                    'start': data.index[0],
                    'end': data.index[-1]
                }
                configs['price_range'][level.value] = {
                    'min': data['low'].min(),
                    'max': data['high'].max()
                }
        
        return configs
    
    def _generate_analysis_summary(self, structure_results: Dict, mapping_results: Dict,
                                 signal_results: Dict, divergence_results: Dict) -> Dict:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        level_results = structure_results.get('level_results', {})
        
        summary = {
            'analysis_quality': self._assess_analysis_quality(level_results),
            'trend_analysis': self._summarize_trends(level_results),
            'signal_analysis': signal_results.get('signal_summary', {}),
            'divergence_analysis': divergence_results.get('divergence_summary', {}),
            'mapping_analysis': {
                'mapping_quality': mapping_results.get('mapping_quality', 0.0),
                'resonance_strength': mapping_results.get('resonance_analysis', {}).get('overall_resonance', 0.0)
            }
        }
        
        return summary
    
    def _assess_analysis_quality(self, level_results: Dict) -> Dict:
        """è¯„ä¼°åˆ†æè´¨é‡"""
        if not level_results:
            return {'overall': 0.0, 'details': 'æ— æ•°æ®'}
        
        quality_scores = []
        details = {}
        
        for level, result in level_results.items():
            # æ•°æ®å®Œæ•´æ€§è¯„åˆ†
            data_completeness = 1.0 if result else 0.0
            
            # ç»“æ„ä¸°å¯Œåº¦è¯„åˆ†
            structure_richness = min(1.0, (
                len(result.get('fenxing_tops', [])) + 
                len(result.get('fenxing_bottoms', [])) + 
                len(result.get('bi_list', [])) + 
                len(result.get('zhongshu_list', []))
            ) / 20.0)
            
            level_score = (data_completeness + structure_richness) / 2
            quality_scores.append(level_score)
            details[level.value] = level_score
        
        overall_quality = sum(quality_scores) / len(quality_scores)
        
        return {
            'overall': overall_quality,
            'details': details,
            'quality_level': 'ä¼˜ç§€' if overall_quality > 0.8 else 'è‰¯å¥½' if overall_quality > 0.6 else 'ä¸€èˆ¬' if overall_quality > 0.4 else 'è¾ƒå·®'
        }
    
    def _summarize_trends(self, level_results: Dict) -> Dict:
        """æ€»ç»“è¶‹åŠ¿åˆ†æ"""
        trends = {}
        
        for level, result in level_results.items():
            trend = result.get('current_trend', TrendDirection.SIDEWAYS)
            trend_strength = result.get('trend_strength', 0.5)
            
            trends[level.value] = {
                'direction': trend.value if hasattr(trend, 'value') else str(trend),
                'strength': trend_strength,
                'zhongshu_count': len(result.get('zhongshu_list', []))
            }
        
        # å¤šçº§åˆ«è¶‹åŠ¿ä¸€è‡´æ€§
        trend_directions = [trends[level]['direction'] for level in trends]
        consistency = len(set(trend_directions)) == 1 if trend_directions else False
        
        return {
            'level_trends': trends,
            'multi_level_consistency': consistency,
            'dominant_trend': max(trends.values(), key=lambda x: x['strength'])['direction'] if trends else 'unknown'
        }
    
    def _summarize_signals(self, signals: List[Dict]) -> Dict:
        """æ€»ç»“ä¿¡å·åˆ†æ"""
        if not signals:
            return {'total': 0, 'buy': 0, 'sell': 0, 'quality': 'æ— ä¿¡å·'}
        
        buy_count = len([s for s in signals if s['signal_type'] == 'buy'])
        sell_count = len([s for s in signals if s['signal_type'] == 'sell'])
        avg_confidence = sum(s['confidence'] for s in signals) / len(signals)
        
        quality = 'ä¿¡å·ä¸°å¯Œ' if len(signals) > 5 else 'ä¿¡å·å……è¶³' if len(signals) > 2 else 'ä¿¡å·ç¨€å°‘'
        
        return {
            'total': len(signals),
            'buy': buy_count,
            'sell': sell_count,
            'average_confidence': avg_confidence,
            'quality': quality
        }
    
    def _summarize_divergences(self, divergences: List[Dict]) -> Dict:
        """æ€»ç»“èƒŒç¦»åˆ†æ"""
        if not divergences:
            return {'total': 0, 'top': 0, 'bottom': 0}
        
        top_count = len([d for d in divergences if d['type'] == 'top_divergence'])
        bottom_count = len([d for d in divergences if d['type'] == 'bottom_divergence'])
        
        return {
            'total': len(divergences),
            'top': top_count,
            'bottom': bottom_count
        }
    
    def _get_current_recommendation(self, signals: List[Dict]) -> Dict:
        """è·å–å½“å‰æ“ä½œå»ºè®®"""
        if not signals:
            return {'action': 'hold', 'reason': 'æš‚æ— æ˜ç¡®ä¿¡å·', 'confidence': 0.5}
        
        # è·å–æœ€è¿‘çš„ä¿¡å·
        recent_signals = sorted(signals, key=lambda x: x['timestamp'], reverse=True)[:3]
        
        if not recent_signals:
            return {'action': 'hold', 'reason': 'æš‚æ— æ˜ç¡®ä¿¡å·', 'confidence': 0.5}
        
        latest_signal = recent_signals[0]
        
        # æ£€æŸ¥ä¿¡å·ä¸€è‡´æ€§
        recent_types = [s['signal_type'] for s in recent_signals]
        consistency = len(set(recent_types))
        
        confidence = latest_signal['confidence']
        if consistency == 1:  # ä¿¡å·ä¸€è‡´
            confidence += 0.2
        
        action = latest_signal['signal_type']
        reason = f"{latest_signal['description']} (ç½®ä¿¡åº¦: {confidence:.2f})"
        
        return {
            'action': action,
            'reason': reason,
            'confidence': min(confidence, 1.0),
            'signal_level': latest_signal['signal_level'],
            'timeframe': latest_signal['timeframe']
        }
    
    def _generate_operation_advice(self, signal_results: Dict, analysis_summary: Dict) -> Dict:
        """ç”Ÿæˆæ“ä½œå»ºè®®"""
        recommendation = signal_results.get('current_recommendation', {})
        analysis_quality = analysis_summary.get('analysis_quality', {})
        
        # åŸºäºåˆ†æè´¨é‡è°ƒæ•´å»ºè®®å¯ä¿¡åº¦
        quality_score = analysis_quality.get('overall', 0.5)
        adjusted_confidence = recommendation.get('confidence', 0.5) * quality_score
        
        # é£é™©è¯„ä¼°
        risk_level = 'high' if adjusted_confidence < 0.4 else 'medium' if adjusted_confidence < 0.7 else 'low'
        
        return {
            'primary_action': recommendation.get('action', 'hold'),
            'confidence_level': adjusted_confidence,
            'risk_level': risk_level,
            'detailed_advice': recommendation.get('reason', ''),
            'supporting_timeframes': recommendation.get('timeframe', ''),
            'caution_notes': self._generate_caution_notes(risk_level, analysis_quality)
        }
    
    def _generate_caution_notes(self, risk_level: str, analysis_quality: Dict) -> List[str]:
        """ç”Ÿæˆæ³¨æ„äº‹é¡¹"""
        notes = []
        
        if risk_level == 'high':
            notes.append("âš ï¸ ä¿¡å·å¼ºåº¦è¾ƒå¼±ï¼Œå»ºè®®è°¨æ…æ“ä½œ")
        
        if analysis_quality.get('overall', 0) < 0.6:
            notes.append("âš ï¸ åˆ†ææ•°æ®è´¨é‡ä¸€èˆ¬ï¼Œå»ºè®®ç»“åˆå…¶ä»–åˆ†ææ–¹æ³•")
        
        notes.append("ğŸ“ˆ ç¼ è®ºåˆ†æä»…ä¾›å‚è€ƒï¼Œè¯·ç»“åˆåŸºæœ¬é¢åˆ†æ")
        notes.append("ğŸ’° è¯·æ§åˆ¶ä»“ä½ï¼Œè®¾ç½®æ­¢æŸ")
        
        return notes
    
    def _empty_analysis_result(self, symbol: str) -> Dict[str, Any]:
        """ç©ºåˆ†æç»“æœ"""
        return {
            'symbol': symbol,
            'analysis_timestamp': datetime.now(),
            'structure_results': {'level_results': {}},
            'mapping_results': {},
            'signal_results': {'validated_signals': [], 'signal_summary': {'total': 0}},
            'divergence_results': {'divergence_signals': []},
            'visualization_data': VisualizationData(
                kline_data={},
                fenxing_data={},
                bi_data={},
                xianduan_data={},
                zhongshu_data={},
                trading_signals=[],
                divergence_signals=[],
                structure_mappings=[],
                zhongshu_inheritances=[],
                bollinger_bands={},
                analysis_summary={'total_levels': 0},
                chart_configs={}
            ),
            'analysis_summary': {'analysis_quality': {'overall': 0.0}},
            'operation_advice': {'primary_action': 'hold', 'confidence_level': 0.0}
        }
    
    def _empty_level_result(self) -> Dict:
        """ç©ºçº§åˆ«ç»“æœ"""
        return {
            'fenxing_tops': [],
            'fenxing_bottoms': [],
            'bi_list': [],
            'xd_list': [],
            'zhongshu_list': [],
            'current_trend': TrendDirection.SIDEWAYS,
            'trend_strength': 0.0
        }
    
    def save_analysis_result(self, result: Dict[str, Any], save_path: str) -> bool:
        """ä¿å­˜åˆ†æç»“æœ"""
        try:
            # è½¬æ¢datetimeå¯¹è±¡ä¸ºå­—ç¬¦ä¸²ä»¥æ”¯æŒJSONåºåˆ—åŒ–
            serializable_result = self._make_json_serializable(result)
            
            with open(save_path, 'w', encoding='utf-8') as f:
                json.dump(serializable_result, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜: {save_path}")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")
            return False
    
    def _make_json_serializable(self, obj):
        """ä½¿å¯¹è±¡å¯JSONåºåˆ—åŒ–"""
        if isinstance(obj, dict):
            return {k: self._make_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        elif isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, pd.DataFrame):
            return obj.to_dict('records')
        elif hasattr(obj, '__dict__'):
            return self._make_json_serializable(obj.__dict__)
        elif isinstance(obj, (TrendLevel, TrendDirection, FenXingType)):
            return obj.value
        else:
            return obj


# æ ¸å¿ƒå¼•æ“æ¨¡å—ï¼Œä¸åŒ…å«æµ‹è¯•é€»è¾‘
# æ‰€æœ‰æµ‹è¯•åº”è¯¥åœ¨ç‹¬ç«‹çš„æµ‹è¯•è„šæœ¬ä¸­è¿›è¡Œ