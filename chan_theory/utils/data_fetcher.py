#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼ è®ºæ•°æ®è·å–å™¨
ä»çœŸå®æ•°æ®åº“è·å–å¤šå‘¨æœŸKçº¿æ•°æ®å’ŒæŠ€æœ¯å› å­æ•°æ®
"""

import sys
import os
from datetime import datetime, timedelta
from typing import Dict, Optional, List
import pandas as pd
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.append(project_root)

# æ·»åŠ APIè·¯å¾„
api_path = os.path.join(project_root, 'api')
sys.path.append(api_path)

try:
    from db_handler import DBHandler
except ImportError:
    # å¦‚æœè¿˜æ˜¯å¯¼å…¥å¤±è´¥ï¼Œå°è¯•å®Œæ•´è·¯å¾„
    sys.path.append('/Users/libing/kk_Projects/kk_Stock/kk_stock_backend/api')
    from db_handler import DBHandler
# æ·»åŠ ç¼ è®ºç›®å½•è·¯å¾„
chan_theory_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(chan_theory_dir)

from analysis.chan_theory.models.chan_theory_models import TrendLevel


class ChanDataFetcher:
    """ç¼ è®ºæ•°æ®è·å–å™¨"""
    
    
    def __init__(self, db_handler=None):
        """åˆå§‹åŒ–æ•°æ®è·å–å™¨"""
        if db_handler:
            self.db_handler = db_handler
        else:
            self.db_handler = DBHandler()
        
        # æ•°æ®åº“é›†åˆæ˜ å°„
        self.collection_mapping = {
            TrendLevel.MIN5: 'stock_kline_5min',
            TrendLevel.MIN30: 'stock_kline_30min',
            TrendLevel.DAILY: 'stock_kline_daily'
        }
        
        # æ—¶é—´å­—æ®µæ˜ å°„ï¼ˆåˆ†é’Ÿçº§åˆ«ä½¿ç”¨trade_timeï¼Œæ—¥çº§ä½¿ç”¨trade_dateï¼‰
        self.time_field_mapping = {
            TrendLevel.MIN5: 'trade_time',
            TrendLevel.MIN30: 'trade_time', 
            TrendLevel.DAILY: 'trade_date'
        }
        
        # æŠ€æœ¯å› å­é›†åˆ
        self.factor_collection = 'stock_factor_pro'
        
        print("ğŸ“Š ç¼ è®ºæ•°æ®è·å–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def get_kline_data(self, symbol: str, level: TrendLevel, 
                      start_date: datetime, end_date: datetime) -> pd.DataFrame:
        """
        è·å–æŒ‡å®šå‘¨æœŸçš„Kçº¿æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            level: æ—¶é—´å‘¨æœŸ
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            Kçº¿æ•°æ®DataFrame
        """
        try:
            collection_name = self.collection_mapping[level]
            collection = self.db_handler.get_collection(collection_name)
            
            # æ ¹æ®ä¸åŒçº§åˆ«ä½¿ç”¨ä¸åŒçš„æ—¶é—´å­—æ®µå’Œæ ¼å¼
            time_field = self.time_field_mapping[level]
            
            if level in [TrendLevel.MIN5, TrendLevel.MIN30]:
                # åˆ†é’Ÿçº§åˆ«ä½¿ç”¨trade_timeå­—æ®µï¼Œæ ¼å¼ä¸º"YYYY-MM-DD HH:MM:SS"
                start_time_str = start_date.strftime('%Y-%m-%d 09:30:00')
                end_time_str = end_date.strftime('%Y-%m-%d 15:00:00')
                query = {
                    'ts_code': symbol,
                    time_field: {
                        '$gte': start_time_str,
                        '$lte': end_time_str
                    }
                }
            else:
                # æ—¥çº§ä½¿ç”¨trade_dateå­—æ®µï¼Œæ ¼å¼ä¸ºYYYYMMDD
                query = {
                    'ts_code': symbol,
                    time_field: {
                        '$gte': start_date.strftime('%Y%m%d'),
                        '$lte': end_date.strftime('%Y%m%d')
                    }
                }
            
            print(f"ğŸ” æŸ¥è¯¢ {symbol} {level.value} çº§åˆ«æ•°æ®...")
            cursor = collection.find(query).sort(time_field, 1)
            data_list = list(cursor)
            
            if not data_list:
                print(f"âš ï¸ æœªæ‰¾åˆ° {symbol} {level.value} çº§åˆ«çš„Kçº¿æ•°æ®")
                # å°è¯•æŸ¥çœ‹æ•°æ®åº“ä¸­æ˜¯å¦æœ‰è¯¥è‚¡ç¥¨çš„ä»»ä½•æ•°æ®
                test_query = {'ts_code': symbol}
                test_cursor = collection.find(test_query).limit(1)
                test_data = list(test_cursor)
                if test_data:
                    print(f"ğŸ’¡ æ•°æ®åº“ä¸­å­˜åœ¨ {symbol} çš„æ•°æ®ï¼Œä½†å¯èƒ½æ—¥æœŸèŒƒå›´ä¸åŒ¹é…")
                else:
                    print(f"âŒ æ•°æ®åº“ä¸­å®Œå…¨æ²¡æœ‰ {symbol} çš„æ•°æ®")
                return pd.DataFrame()
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(data_list)
            
            # ä¸´æ—¶è°ƒè¯•ï¼šè¾“å‡ºåŸå§‹æ•°æ®ä¿¡æ¯
            if level == TrendLevel.DAILY and len(df) > 0:
                print(f"ğŸ” {symbol} æ—¥çº¿åŸå§‹æ•°æ®è°ƒè¯•ä¿¡æ¯:")
                print(f"   åˆ—å: {list(df.columns)}")
                print(f"   å‰3è¡Œæ•°æ®:")
                for i, (index, row) in enumerate(df.head(3).iterrows()):
                    if i < 3:
                        print(f"     è¡Œ{i}: trade_date={row.get('trade_date', 'N/A')}, open={row.get('open', 'N/A')}, high={row.get('high', 'N/A')}, low={row.get('low', 'N/A')}, close={row.get('close', 'N/A')}")
            
            # æ•°æ®æ¸…æ´—å’Œæ ¼å¼åŒ–
            import logging
            logger = logging.getLogger(__name__)
            logger.info(f"ğŸ” {symbol} {level.value} çº§åˆ«æ•°æ®æ¸…æ´—å‰: {len(df)} æ¡è®°å½•")
            df = self._clean_kline_data(df, level)
            logger.info(f"ğŸ” {symbol} {level.value} çº§åˆ«æ•°æ®æ¸…æ´—å: {len(df)} æ¡è®°å½•")
            
            print(f"âœ… è·å– {symbol} {level.value} Kçº¿æ•°æ®: {len(df)} æ¡è®°å½•")
            return df
            
        except Exception as e:
            print(f"âŒ è·å–Kçº¿æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_factor_data(self, symbol: str, start_date: datetime, end_date: datetime) -> pd.DataFrame:
        """
        è·å–æŠ€æœ¯å› å­æ•°æ®ï¼ˆåŒ…å«å¸ƒæ—å¸¦ï¼‰
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            æŠ€æœ¯å› å­æ•°æ®DataFrame
        """
        try:
            collection = self.db_handler.get_collection(self.factor_collection)
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query = {
                'ts_code': symbol,
                'trade_date': {
                    '$gte': start_date.strftime('%Y%m%d'),
                    '$lte': end_date.strftime('%Y%m%d')
                }
            }
            
            # æŸ¥è¯¢æ•°æ®
            cursor = collection.find(query).sort('trade_date', 1)
            data_list = list(cursor)
            
            if not data_list:
                print(f"âš ï¸ æœªæ‰¾åˆ° {symbol} çš„æŠ€æœ¯å› å­æ•°æ®")
                return pd.DataFrame()
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(data_list)
            
            # æ•°æ®æ¸…æ´—å’Œæ ¼å¼åŒ–
            df = self._clean_factor_data(df)
            
            print(f"âœ… è·å– {symbol} æŠ€æœ¯å› å­æ•°æ®: {len(df)} æ¡è®°å½•")
            return df
            
        except Exception as e:
            print(f"âŒ è·å–æŠ€æœ¯å› å­æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_multi_timeframe_data(self, symbol: str, start_date: datetime, 
                                end_date: datetime) -> Dict[TrendLevel, pd.DataFrame]:
        """
        è·å–å¤šå‘¨æœŸæ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            å¤šå‘¨æœŸæ•°æ®å­—å…¸
        """
        print(f"ğŸ“Š è·å– {symbol} å¤šå‘¨æœŸæ•°æ®...")
        
        multi_data = {}
        
        # è·å–å„ä¸ªå‘¨æœŸçš„Kçº¿æ•°æ®
        for level in TrendLevel:
            kline_data = self.get_kline_data(symbol, level, start_date, end_date)
            if not kline_data.empty:
                # ä¸ºåˆ†é’Ÿçº§åˆ«è®¡ç®—æŠ€æœ¯å› å­
                if level in [TrendLevel.MIN5, TrendLevel.MIN30]:
                    kline_data = self._calculate_minute_technical_factors(kline_data, level)
                
                multi_data[level] = kline_data
        
        # è·å–æ—¥çº¿æŠ€æœ¯å› å­æ•°æ®
        if TrendLevel.DAILY in multi_data:
            factor_data = self.get_factor_data(symbol, start_date, end_date)
            
            # å°†æŠ€æœ¯å› å­æ•°æ®åˆå¹¶åˆ°æ—¥çº¿æ•°æ®ä¸­
            if not factor_data.empty:
                daily_data = multi_data[TrendLevel.DAILY]
                
                # æŒ‰äº¤æ˜“æ—¥æœŸåˆå¹¶ï¼ˆå¤„ç†ç±»å‹ä¸åŒ¹é…é—®é¢˜ï¼‰
                if 'original_time_field' in daily_data.columns:
                    try:
                        daily_data_with_date = daily_data.copy()
                        
                        # ç¡®ä¿ä¸¤ä¸ªæ•°æ®æºçš„trade_dateå­—æ®µç±»å‹ä¸€è‡´
                        daily_data_with_date['trade_date'] = daily_data_with_date['original_time_field'].astype(str)
                        factor_data_copy = factor_data.copy()
                        factor_data_copy['trade_date'] = factor_data_copy['trade_date'].astype(str)
                        
                        merged_data = pd.merge(
                            daily_data_with_date, 
                            factor_data_copy, 
                            on='trade_date', 
                            how='left',
                            suffixes=('', '_factor')
                        )
                        
                        # ç§»é™¤ä¸´æ—¶çš„trade_dateåˆ—
                        merged_data = merged_data.drop('trade_date', axis=1, errors='ignore')
                        multi_data[TrendLevel.DAILY] = merged_data
                        print(f"âœ… æ—¥çº¿æ•°æ®ä¸æ•°æ®åº“æŠ€æœ¯å› å­åˆå¹¶å®Œæˆ")
                    except Exception as merge_error:
                        print(f"âš ï¸ æ•°æ®åˆå¹¶å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ—¥çº¿æ•°æ®: {merge_error}")
                        # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œä¸ºæ—¥çº¿è®¡ç®—æŠ€æœ¯å› å­
                        multi_data[TrendLevel.DAILY] = self._calculate_minute_technical_factors(
                            multi_data[TrendLevel.DAILY], TrendLevel.DAILY
                        )
            else:
                # å¦‚æœæ²¡æœ‰æ•°æ®åº“ä¸­çš„æŠ€æœ¯å› å­ï¼Œä¸ºæ—¥çº¿è®¡ç®—åŸºç¡€æŠ€æœ¯å› å­
                multi_data[TrendLevel.DAILY] = self._calculate_minute_technical_factors(
                    multi_data[TrendLevel.DAILY], TrendLevel.DAILY
                )
                print(f"âœ… æ—¥çº¿æ•°æ®è®¡ç®—æŠ€æœ¯å› å­å®Œæˆ")
        
        print(f"âœ… å¤šå‘¨æœŸæ•°æ®è·å–å®Œæˆï¼ŒåŒ…å« {len(multi_data)} ä¸ªå‘¨æœŸ")
        return multi_data
    
    def _clean_kline_data(self, df: pd.DataFrame, level: TrendLevel) -> pd.DataFrame:
        """æ¸…æ´—Kçº¿æ•°æ®"""
        if df.empty:
            return df
        
        # æ ¹æ®ä¸åŒçº§åˆ«å¤„ç†æ—¶é—´å­—æ®µ
        time_field = self.time_field_mapping[level]
        required_fields = [time_field, 'open', 'high', 'low', 'close', 'vol']
        missing_fields = [field for field in required_fields if field not in df.columns]
        
        if missing_fields:
            print(f"âš ï¸ {level.value} æ•°æ®ç¼ºå°‘å­—æ®µ: {missing_fields}")
            return pd.DataFrame()
        
        # æ•°æ®ç±»å‹è½¬æ¢ - æ ¹æ®çº§åˆ«å¤„ç†æ—¶é—´å­—æ®µ
        if level in [TrendLevel.MIN5, TrendLevel.MIN30]:
            # åˆ†é’Ÿçº§åˆ«ï¼štrade_timeå­—æ®µä¿æŒåŸå§‹æ ¼å¼"YYYY-MM-DD HH:MM:SS"
            df['datetime_index'] = pd.to_datetime(df[time_field], errors='coerce')
            print(f"â„¹ï¸ {level.value}çº§åˆ«æ—¶é—´å­—æ®µç¤ºä¾‹: {df[time_field].iloc[0] if len(df) > 0 else 'N/A'}")
        else:
            # æ—¥çº§ï¼štrade_dateå­—æ®µè½¬æ¢ä¸ºæ—¥æœŸæ ¼å¼
            print(f"â„¹ï¸ {level.value}çº§åˆ«åŸå§‹æ—¶é—´å­—æ®µç¤ºä¾‹: {df[time_field].iloc[0] if len(df) > 0 else 'N/A'}")
            df['datetime_index'] = pd.to_datetime(df[time_field], format='%Y%m%d', errors='coerce')
            
            # æ£€æŸ¥è½¬æ¢åçš„æ—¶é—´å­—æ®µ
            nan_count = df['datetime_index'].isna().sum()
            print(f"â„¹ï¸ {level.value}çº§åˆ«æ—¶é—´è½¬æ¢ç»“æœ: {len(df) - nan_count}/{len(df)} æ¡æˆåŠŸ")
            if nan_count > 0:
                print(f"âš ï¸ {level.value}çº§åˆ«æ—¶é—´è½¬æ¢å¤±è´¥çš„å‰5ä¸ªå€¼:")
                failed_values = df[df['datetime_index'].isna()][time_field].head(5).tolist()
                print(f"   {failed_values}")
        
        # ä»·æ ¼å­—æ®µè½¬æ¢ä¸ºfloat
        price_fields = ['open', 'high', 'low', 'close']
        for field in price_fields:
            original_count = len(df)
            df[field] = pd.to_numeric(df[field], errors='coerce')
            nan_count = df[field].isna().sum()
            if nan_count > 0:
                print(f"âš ï¸ {level.value}çº§åˆ« {field} å­—æ®µè½¬æ¢å¤±è´¥: {nan_count}/{original_count} æ¡")
        
        # æˆäº¤é‡è½¬æ¢
        df['volume'] = pd.to_numeric(df['vol'], errors='coerce')
        
        # æ£€æŸ¥æ¯ä¸ªå­—æ®µçš„NaNæƒ…å†µ
        check_fields = price_fields + ['datetime_index', 'volume']
        print(f"â„¹ï¸ {level.value}çº§åˆ«æ¸…æ´—å‰å­—æ®µå®Œæ•´æ€§æ£€æŸ¥:")
        for field in check_fields:
            nan_count = df[field].isna().sum()
            if nan_count > 0:
                print(f"   {field}: {nan_count}/{len(df)} æ¡NaN")
        
        # åˆ é™¤æ— æ•ˆæ•°æ® - åªåˆ é™¤å…³é”®å­—æ®µä¸ºç©ºçš„æ•°æ®
        critical_fields = price_fields + ['datetime_index']
        df_before = len(df)
        df = df.dropna(subset=critical_fields)
        df_after = len(df)
        
        if df_before != df_after:
            print(f"âš ï¸ {level.value}çº§åˆ«åˆ é™¤æ— æ•ˆæ•°æ®: {df_before} -> {df_after} æ¡ (åˆ é™¤äº† {df_before - df_after} æ¡)")
        
        # è®¾ç½®ç´¢å¼•
        df.set_index('datetime_index', inplace=True)
        df.sort_index(inplace=True)
        
        # æ•°æ®éªŒè¯
        df = df[(df['high'] >= df['low']) & (df['high'] >= df['open']) & 
                (df['high'] >= df['close']) & (df['low'] <= df['open']) & 
                (df['low'] <= df['close'])]
        
        # ä¿ç•™åŸå§‹æ—¶é—´å­—æ®µä¾›å‚è€ƒ
        if time_field in df.columns:
            df['original_time_field'] = df[time_field]
        
        print(f"âœ… {level.value} æ•°æ®æ¸…æ´—å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
        
        return df
    
    def _clean_factor_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…æ´—æŠ€æœ¯å› å­æ•°æ®"""
        if df.empty:
            return df
        
        # æ—¥æœŸè½¬æ¢
        df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')
        
        # å¸ƒæ—å¸¦å­—æ®µæ£€æŸ¥å’Œè½¬æ¢
        bollinger_fields = ['boll_upper_qfq', 'boll_mid_qfq', 'boll_lower_qfq']
        available_bollinger = [field for field in bollinger_fields if field in df.columns]
        
        if available_bollinger:
            for field in available_bollinger:
                df[field] = pd.to_numeric(df[field], errors='coerce')
            print(f"âœ… å‘ç°å¸ƒæ—å¸¦å­—æ®µ: {available_bollinger}")
        else:
            print("âš ï¸ æœªå‘ç°å¸ƒæ—å¸¦å­—æ®µï¼Œå°†ä½¿ç”¨ä»·æ ¼è®¡ç®—")
        
        # å…¶ä»–æŠ€æœ¯æŒ‡æ ‡å­—æ®µè½¬æ¢
        technical_fields = [col for col in df.columns if any(indicator in col.lower() 
                           for indicator in ['macd', 'rsi', 'ma', 'ema', 'kdj'])]
        
        for field in technical_fields:
            df[field] = pd.to_numeric(df[field], errors='coerce')
        
        # è®¾ç½®ç´¢å¼•
        df.set_index('trade_date', inplace=True)
        df.sort_index(inplace=True)
        
        return df
    
    def calculate_bollinger_bands(self, price_data: pd.Series, period: int = 20, 
                                 std_multiplier: float = 2.0) -> Dict[str, pd.Series]:
        """
        è®¡ç®—å¸ƒæ—å¸¦ï¼ˆå½“æ•°æ®åº“ä¸­æ²¡æœ‰æ—¶ä½¿ç”¨ï¼‰
        
        Args:
            price_data: ä»·æ ¼åºåˆ—ï¼ˆé€šå¸¸æ˜¯æ”¶ç›˜ä»·ï¼‰
            period: è®¡ç®—å‘¨æœŸ
            std_multiplier: æ ‡å‡†å·®å€æ•°
            
        Returns:
            å¸ƒæ—å¸¦æ•°æ®å­—å…¸
        """
        # è®¡ç®—ä¸­è½¨ï¼ˆç§»åŠ¨å¹³å‡ï¼‰
        middle = price_data.rolling(window=period).mean()
        
        # è®¡ç®—æ ‡å‡†å·®
        std = price_data.rolling(window=period).std()
        
        # è®¡ç®—ä¸Šè½¨å’Œä¸‹è½¨
        upper = middle + (std * std_multiplier)
        lower = middle - (std * std_multiplier)
        
        return {
            'upper': upper,
            'middle': middle,
            'lower': lower
        }
    
    def _assign_minute_timestamps(self, df: pd.DataFrame, level: TrendLevel) -> pd.DataFrame:
        """
        ä¸ºåˆ†é’Ÿçº§æ•°æ®åˆ†é…å…·ä½“çš„æ—¶é—´æˆ³
        æ¯ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®æŒ‰Aè‚¡äº¤æ˜“æ—¶é—´åˆ†é…åˆ°ä¸åŒæ—¶é—´ç‚¹
        
        Args:
            df: åŸå§‹åˆ†é’Ÿçº§æ•°æ®DataFrame (åªåŒ…å«æ—¥æœŸ)
            level: æ—¶é—´çº§åˆ«
            
        Returns:
            å¸¦æœ‰å…·ä½“æ—¶é—´æˆ³çš„DataFrame
        """
        if df.empty:
            return df
        
        # æ—¥å‘¨æœˆçº§åˆ«ä¸éœ€è¦åˆ†é’Ÿæ—¶é—´æˆ³å¤„ç†
        return df
    
    def _generate_trading_timepoints(self, trade_date: pd.Timestamp, interval_minutes: int) -> list:
        """
        ä¸ºäº¤æ˜“æ—¥ç”ŸæˆAè‚¡äº¤æ˜“æ—¶é—´ç‚¹
        
        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ
            interval_minutes: æ—¶é—´é—´éš”(åˆ†é’Ÿ)
            
        Returns:
            æ—¶é—´ç‚¹åˆ—è¡¨
        """
        timepoints = []
        
        # ä¸Šåˆæ—¶æ®µ: 09:30-11:30 (2å°æ—¶)
        morning_start = trade_date.replace(hour=9, minute=30, second=0)
        morning_end = trade_date.replace(hour=11, minute=30, second=0)
        
        # ä¸‹åˆæ—¶æ®µ: 13:00-15:00 (2å°æ—¶)
        afternoon_start = trade_date.replace(hour=13, minute=0, second=0)
        afternoon_end = trade_date.replace(hour=15, minute=0, second=0)
        
        # ç”Ÿæˆä¸Šåˆæ—¶é—´ç‚¹
        current_time = morning_start
        while current_time <= morning_end:
            timepoints.append(current_time)
            current_time += pd.Timedelta(minutes=interval_minutes)
        
        # ç”Ÿæˆä¸‹åˆæ—¶é—´ç‚¹
        current_time = afternoon_start
        while current_time <= afternoon_end:
            timepoints.append(current_time)
            current_time += pd.Timedelta(minutes=interval_minutes)
        
        return timepoints
    
    def validate_data_quality(self, data: Dict[TrendLevel, pd.DataFrame]) -> Dict[TrendLevel, bool]:
        """
        éªŒè¯æ•°æ®è´¨é‡
        
        Args:
            data: å¤šå‘¨æœŸæ•°æ®
            
        Returns:
            å„å‘¨æœŸæ•°æ®è´¨é‡éªŒè¯ç»“æœ
        """
        validation_results = {}
        
        for level, df in data.items():
            is_valid = True
            issues = []
            
            if df.empty:
                is_valid = False
                issues.append("æ•°æ®ä¸ºç©º")
            else:
                # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
                if df.isnull().any().any():
                    issues.append("å­˜åœ¨ç©ºå€¼")
                
                # æ£€æŸ¥ä»·æ ¼é€»è¾‘
                invalid_price_logic = (df['high'] < df['low']) | \
                                    (df['high'] < df['open']) | \
                                    (df['high'] < df['close']) | \
                                    (df['low'] > df['open']) | \
                                    (df['low'] > df['close'])
                
                if invalid_price_logic.any():
                    issues.append("ä»·æ ¼é€»è¾‘é”™è¯¯")
                
                # æ£€æŸ¥æ•°æ®é‡
                if len(df) < 30:
                    issues.append("æ•°æ®é‡ä¸è¶³")
                    is_valid = False
            
            validation_results[level] = is_valid
            
            if issues:
                print(f"âš ï¸ {level.value} æ•°æ®è´¨é‡é—®é¢˜: {', '.join(issues)}")
            else:
                print(f"âœ… {level.value} æ•°æ®è´¨é‡è‰¯å¥½")
        
        return validation_results
    
    def _calculate_minute_technical_factors(self, df: pd.DataFrame, level: TrendLevel) -> pd.DataFrame:
        """
        ä¸ºåˆ†é’Ÿçº§åˆ«è®¡ç®—æŠ€æœ¯å› å­ï¼ˆåŒ…æ‹¬å¸ƒæ—å¸¦ã€ç§»åŠ¨å¹³å‡ç­‰ï¼‰
        
        Args:
            df: Kçº¿æ•°æ®
            level: æ—¶é—´çº§åˆ«
            
        Returns:
            å¸¦æœ‰æŠ€æœ¯å› å­çš„DataFrame
        """
        if df.empty:
            return df
        
        try:
            print(f"ğŸ“ ä¸º {level.value} çº§åˆ«è®¡ç®—æŠ€æœ¯å› å­...")
            
            # å¤åˆ¶æ•°æ®é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
            df_with_factors = df.copy()
            
            # 1. è®¡ç®—å¸ƒæ—å¸¦ï¼ˆæ¨¡æ‹Ÿç¼ è®ºä¸‰çº¿ï¼‰
            close_price = df_with_factors['close']
            
            # æ ¹æ®ä¸åŒçº§åˆ«è°ƒæ•´å¸ƒæ—å¸¦å‚æ•°
            if level == TrendLevel.MIN5:
                period = 20  # 5åˆ†é’Ÿçº§åˆ«ä½¿ç”²20å‘¨æœŸï¼ˆçº¦100åˆ†é’Ÿï¼‰
                std_multiplier = 2.0
            elif level == TrendLevel.MIN30:
                period = 14  # 30åˆ†é’Ÿçº§åˆ«ä½¿ç”²14å‘¨æœŸï¼ˆçº¦7å°æ—¶ï¼‰
                std_multiplier = 2.0
            else:  # æ—¥çº§
                period = 20  # æ—¥çº§ä½¿ç”¨20å¤©
                std_multiplier = 2.0
            
            bollinger_bands = self.calculate_bollinger_bands(
                close_price, period=period, std_multiplier=std_multiplier
            )
            
            df_with_factors['boll_upper'] = bollinger_bands['upper']
            df_with_factors['boll_mid'] = bollinger_bands['middle']
            df_with_factors['boll_lower'] = bollinger_bands['lower']
            
            # 2. è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
            if level == TrendLevel.MIN5:
                ma_periods = [5, 10, 20]  # 5ã€10ã€20å‘¨æœŸ
            elif level == TrendLevel.MIN30:
                ma_periods = [5, 10, 14]  # 5ã€10ã€14å‘¨æœŸ
            else:  # æ—¥çº§
                ma_periods = [5, 10, 20, 60]  # 5ã€10ã€20ã€60å¤©
            
            for period in ma_periods:
                df_with_factors[f'ma{period}'] = close_price.rolling(window=period).mean()
            
            # 3. è®¡ç®—RSIæŒ‡æ ‡
            rsi_period = 14 if level != TrendLevel.MIN5 else 10
            df_with_factors['rsi'] = self._calculate_rsi(close_price, period=rsi_period)
            
            # 4. è®¡ç®—MACDæŒ‡æ ‡
            if level == TrendLevel.MIN5:
                fast_period, slow_period, signal_period = 12, 26, 9
            elif level == TrendLevel.MIN30:
                fast_period, slow_period, signal_period = 8, 17, 6
            else:
                fast_period, slow_period, signal_period = 12, 26, 9
            
            macd_data = self._calculate_macd(
                close_price, fast_period=fast_period, 
                slow_period=slow_period, signal_period=signal_period
            )
            
            df_with_factors['macd'] = macd_data['macd']
            df_with_factors['macd_signal'] = macd_data['signal']
            df_with_factors['macd_hist'] = macd_data['histogram']
            
            # 5. è®¡ç®—æˆäº¤é‡æŒ‡æ ‡
            volume_ma_period = 10 if level == TrendLevel.MIN5 else 14
            df_with_factors['vol_ma'] = df_with_factors['volume'].rolling(window=volume_ma_period).mean()
            df_with_factors['vol_ratio'] = df_with_factors['volume'] / df_with_factors['vol_ma']
            
            # 6. è®¡ç®—ä»·æ ¼ä½ç½®æŒ‡æ ‡ï¼ˆåœ¨å¸ƒæ—å¸¦ä¸­çš„ä½ç½®ï¼‰
            upper = df_with_factors['boll_upper']
            lower = df_with_factors['boll_lower']
            df_with_factors['boll_position'] = (close_price - lower) / (upper - lower)
            
            # 7. è®¡ç®—æ³¢åŠ¨ç‡
            volatility_period = 10 if level == TrendLevel.MIN5 else 14
            df_with_factors['volatility'] = close_price.pct_change().rolling(window=volatility_period).std()
            
            print(f"âœ… {level.value} çº§åˆ«æŠ€æœ¯å› å­è®¡ç®—å®Œæˆ")
            return df_with_factors
            
        except Exception as e:
            print(f"âŒ {level.value} çº§åˆ«æŠ€æœ¯å› å­è®¡ç®—å¤±è´¥: {e}")
            return df
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """
        è®¡ç®—RSIæŒ‡æ ‡
        
        Args:
            prices: ä»·æ ¼åºåˆ—
            period: è®¡ç®—å‘¨æœŸ
            
        Returns:
            RSIæ•°æ®
        """
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def _calculate_macd(self, prices: pd.Series, fast_period: int = 12, 
                       slow_period: int = 26, signal_period: int = 9) -> Dict[str, pd.Series]:
        """
        è®¡ç®—MACDæŒ‡æ ‡
        
        Args:
            prices: ä»·æ ¼åºåˆ—
            fast_period: å¿«çº¿å‘¨æœŸ
            slow_period: æ…¢çº¿å‘¨æœŸ
            signal_period: ä¿¡å·çº¿å‘¨æœŸ
            
        Returns:
            MACDæ•°æ®å­—å…¸
        """
        # è®¡ç®—æŒ‡æ•°ç§»åŠ¨å¹³å‡
        ema_fast = prices.ewm(span=fast_period).mean()
        ema_slow = prices.ewm(span=slow_period).mean()
        
        # MACDçº¿ = å¿«çº¿ - æ…¢çº¿
        macd_line = ema_fast - ema_slow
        
        # ä¿¡å·çº¿ = MACDçš„æŒ‡æ•°ç§»åŠ¨å¹³å‡
        signal_line = macd_line.ewm(span=signal_period).mean()
        
        # æŸ±çŠ¶å›¾ = MACDçº¿ - ä¿¡å·çº¿
        histogram = macd_line - signal_line
        
        return {
            'macd': macd_line,
            'signal': signal_line,
            'histogram': histogram
        }