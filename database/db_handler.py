from pymongo import MongoClient, UpdateOne
from pymongo.errors import BulkWriteError, ServerSelectionTimeoutError, ConnectionFailure, NetworkTimeout
import os
from dotenv import load_dotenv
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any
import pymongo
from pymongo import timeout
import logging
import time
from functools import wraps

load_dotenv()

# æ•°æ®åº“é…ç½®
LOCAL_MONGO_URI = "mongodb://root:example@127.0.0.1:27017/quant_analysis?authSource=admin"
DB_NAME = os.getenv("DB_NAME", "quant_analysis")

def retry_on_connection_error(max_retries=3, delay=2):
    """é‡è¯•è£…é¥°å™¨ï¼Œç”¨äºå¤„ç†æ•°æ®åº“è¿æ¥é”™è¯¯"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except (ConnectionFailure, NetworkTimeout, ServerSelectionTimeoutError, Exception) as e:
                    if attempt == max_retries - 1:
                        raise e
                    logging.warning(f"è¿æ¥å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                    time.sleep(delay * (attempt + 1))  # æŒ‡æ•°é€€é¿
            return None
        return wrapper
    return decorator

class DBHandler:
    """æœ¬åœ°MongoDBæ•°æ®åº“å¤„ç†å™¨"""
    
    def __init__(self):
        """
        åˆå§‹åŒ–æœ¬åœ°æ•°æ®åº“è¿æ¥
        """
        self.logger = self._setup_logger()
        
        # åˆå§‹åŒ–è¿æ¥çŠ¶æ€
        self.client = None
        self.db = None
        self.local_available = False
        
        # å»ºç«‹æ•°æ®åº“è¿æ¥
        self._connect_database()
        
    def _setup_logger(self):
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('DBHandler')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _connect_database(self):
        """å»ºç«‹æœ¬åœ°æ•°æ®åº“è¿æ¥"""
        try:
            self.logger.info("ğŸ  è¿æ¥æœ¬åœ°æ•°æ®åº“...")
            self.client = MongoClient(
                LOCAL_MONGO_URI,
                serverSelectionTimeoutMS=30000,  # 30ç§’
                connectTimeoutMS=30000,           # 30ç§’
                socketTimeoutMS=120000,           # 2åˆ†é’Ÿ
                maxPoolSize=50,                   # è¿æ¥æ± å¤§å°
                minPoolSize=10,                   # æœ€å°è¿æ¥æ± 
                maxIdleTimeMS=60000,              # ç©ºé—²è¶…æ—¶
                retryWrites=True,
                w=1,
                heartbeatFrequencyMS=30000        # å¿ƒè·³é¢‘ç‡
            )
            # æµ‹è¯•è¿æ¥
            self.client.admin.command('ismaster')
            self.db = self.client[DB_NAME]
            self.local_available = True
            
            local_info = self.client.server_info()
            print("âœ… æœ¬åœ°MongoDBè¿æ¥æˆåŠŸ")
            print(f"ğŸ“ æœ¬åœ°åœ°å€: 127.0.0.1:27017")
            print(f"ğŸ”§ æœ¬åœ°ç‰ˆæœ¬: {local_info['version']}")
            
        except Exception as e:
            print(f"âŒ æœ¬åœ°æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            print("ğŸ’¡ è¯·ç¡®ä¿æœ¬åœ°MongoDBå®¹å™¨æ­£åœ¨è¿è¡Œ:")
            print("   cd database && docker-compose -f docker-compose.single.yml up -d")
            self.local_available = False
            raise Exception("æ— æ³•è¿æ¥åˆ°æœ¬åœ°æ•°æ®åº“ï¼Œè¯·æ£€æŸ¥æœ¬åœ°MongoDBæœåŠ¡")

    def get_collection(self, collection_name):
        """è·å–æœ¬åœ°æ•°æ®åº“é›†åˆ"""
        if self.local_available:
            return self.db[collection_name]
        else:
            raise Exception("æœ¬åœ°æ•°æ®åº“ä¸å¯ç”¨")
    
    def get_local_collection(self, collection_name):
        """è·å–æœ¬åœ°æ•°æ®åº“é›†åˆï¼ˆä¸ get_collection ç›¸åŒï¼Œä¿ç•™ä»¥å…¼å®¹ï¼‰"""
        return self.get_collection(collection_name)

    def find_data(self, collection_name: str, query: Dict, sort: List[tuple] = None, limit: int = None) -> List[Dict]:
        """æŸ¥è¯¢æ•°æ®åº“æ•°æ®
        
        Args:
            collection_name: é›†åˆåç§°
            query: æŸ¥è¯¢æ¡ä»¶
            sort: æ’åºæ¡ä»¶ï¼Œæ ¼å¼ä¸º[('field', 1/-1)]ï¼Œ1ä¸ºå‡åºï¼Œ-1ä¸ºé™åº
            limit: é™åˆ¶è¿”å›æ•°é‡
            
        Returns:
            List[Dict]: æŸ¥è¯¢ç»“æœåˆ—è¡¨
        """
        try:
            collection = self.get_collection(collection_name)
            cursor = collection.find(query)
            
            # åº”ç”¨æ’åº
            if sort:
                cursor = cursor.sort(sort)
            
            # åº”ç”¨é™åˆ¶
            if limit:
                cursor = cursor.limit(limit)
                
            return list(cursor)
        except Exception as e:
            logging.error(f"æŸ¥è¯¢æ•°æ®å¤±è´¥: {e}")
            return []


    
    def _write_to_local(self, collection_name, updates, batch_size):
        """å†™å…¥æœ¬åœ°æ•°æ®åº“çš„å†…éƒ¨æ–¹æ³•"""
        if not self.local_available:
            return False, 0, 0
        
        try:
            print(f"ğŸ  å†™å…¥æœ¬åœ°æ•°æ®åº“: {collection_name}")
            collection = self.db[collection_name]
            
            total_upserted = 0
            total_modified = 0
            batch_count = 0
            total_batches = (len(updates) + batch_size - 1) // batch_size
            
            for i in range(0, len(updates), batch_size):
                batch = updates[i:i + batch_size]
                batch_count += 1
                
                try:
                    result = collection.bulk_write(batch, ordered=False)
                    total_upserted += result.upserted_count
                    total_modified += result.modified_count
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    if batch_count % 10 == 0 or batch_count == total_batches:
                        print(f"   ğŸ“ è¿›åº¦: {batch_count}/{total_batches} æ‰¹æ¬¡")
                        
                except BulkWriteError as bwe:
                    total_upserted += bwe.details.get('nUpserted', 0)
                    total_modified += bwe.details.get('nModified', 0)
                    error_count = len(bwe.details.get('writeErrors', []))
                    if error_count > 0:
                        logging.warning(f"æ‰¹æ¬¡ {batch_count} éƒ¨åˆ†å¤±è´¥: {error_count} ä¸ªé”™è¯¯")
            
            print(f"âœ… æœ¬åœ°å†™å…¥æˆåŠŸ: æ–°å¢{total_upserted} æ›´æ–°{total_modified}")
            return True, total_upserted, total_modified
            
        except Exception as e:
            logging.error(f"æœ¬åœ°å†™å…¥å¤±è´¥: {e}")
            return False, 0, 0
    
    def _get_optimal_batch_size(self, data_size, collection_name):
        """æ ¹æ®æ•°æ®é‡å’Œé›†åˆç±»å‹åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°"""
        # åŸºç¡€æ‰¹æ¬¡å¤§å°
        if data_size > 100000:  # è¶…è¿‡10ä¸‡æ¡è®°å½•
            base_size = 200
        elif data_size > 10000:  # è¶…è¿‡1ä¸‡æ¡è®°å½•
            base_size = 500
        else:
            base_size = 1000
        
        # æ ¹æ®é›†åˆç±»å‹è°ƒæ•´
        if 'daily' in collection_name.lower():
            return min(base_size, 800)  # æ—¥çº¿æ•°æ®é€šå¸¸è¾ƒå¤§
        elif 'basic' in collection_name.lower():
            return min(base_size, 1500)  # åŸºç¡€ä¿¡æ¯æ•°æ®è¾ƒå°
        else:
            return base_size

    def bulk_upsert(self, collection_name, data, unique_keys):
        """æ‰¹é‡æ›´æ–°æ’å…¥æ•°æ®åˆ°æœ¬åœ°æ•°æ®åº“"""
        if not data:
            print(f"æ²¡æœ‰æ•°æ®éœ€è¦æ’å…¥æˆ–æ›´æ–°åˆ°é›†åˆ {collection_name}")
            return

        # å‡†å¤‡æ‰¹é‡æ“ä½œ
        updates = []
        for item in data:
            filter_query = {key: item[key] for key in unique_keys if key in item}
            updates.append(UpdateOne(filter_query, {'$set': item}, upsert=True))

        # åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°
        batch_size = self._get_optimal_batch_size(len(data), collection_name)
        print(f"ğŸ“Š æ•°æ®é‡: {len(data):,} æ¡ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size}")
        
        # å†™å…¥æœ¬åœ°æ•°æ®åº“
        if not self.local_available:
            logging.error("âŒ æœ¬åœ°æ•°æ®åº“ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæ•°æ®é‡‡é›†")
            raise Exception("æœ¬åœ°æ•°æ®åº“ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æœ¬åœ°MongoDBæœåŠ¡")

        try:
            success, upserted, modified = self._write_to_local(collection_name, updates, batch_size)
            if success:
                print(f"ğŸ¯ æ•°æ®åº“å†™å…¥å®Œæˆ: {collection_name}")
            else:
                logging.error(f"âŒ æ•°æ®åº“å†™å…¥å¤±è´¥: {collection_name}")
                raise Exception("æ•°æ®åº“å†™å…¥å¤±è´¥")
        except Exception as e:
            logging.error(f"âŒ æ•°æ®åº“å†™å…¥å¤±è´¥: {e}")
            raise e

    def __del__(self):
        """å®‰å…¨å…³é—­MongoDBè¿æ¥"""
        try:
            if hasattr(self, 'client') and self.client is not None:
                self.client.close()
        except (ImportError, AttributeError, TypeError):
            # Pythonå…³é—­æ—¶æ¨¡å—å¯èƒ½å·²è¢«æ¸…ç†ï¼Œå¿½ç•¥è¿™äº›é”™è¯¯
            pass

    def get_kline_data(self, stock_code: str, days: int) -> Optional[pd.DataFrame]:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨çš„Kçº¿æ•°æ®
        
        Args:
            stock_code (str): è‚¡ç¥¨ä»£ç 
            days (int): è·å–æœ€è¿‘çš„å¤©æ•°

        Returns:
            Optional[pd.DataFrame]: åŒ…å«Kçº¿æ•°æ®çš„DataFrameï¼Œå¦‚æœæ— æ•°æ®åˆ™è¿”å›None
        """
        try:
            collection = self.db.get_collection('stock_kline_daily')
            
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            
            query = {
                'ts_code': stock_code,
                'trade_date': {
                    '$gte': start_date,
                    '$lte': end_date
                }
            }
            
            cursor = collection.find(query).sort('trade_date', pymongo.ASCENDING)
            data = list(cursor)
            
            if not data:
                return None
            
            df = pd.DataFrame(data)
            # ç¡®ä¿å…³é”®åˆ—å­˜åœ¨
            required_cols = ['trade_date', 'open', 'high', 'low', 'close', 'vol']
            if not all(col in df.columns for col in required_cols):
                print("âŒ Kçº¿æ•°æ®ç¼ºå°‘å…³é”®åˆ—")
                return None

            # ç±»å‹è½¬æ¢
            for col in ['open', 'high', 'low', 'close', 'vol']:
                df[col] = pd.to_numeric(df[col])

            return df

        except Exception as e:
            print(f"âŒ ä»æ•°æ®åº“è·å–Kçº¿æ•°æ®å¤±è´¥: {e}")
            return None

    def get_latest_date_for_code(self, collection_name: str, ts_code: str) -> Optional[datetime]:
        """è·å–æŒ‡å®šä»£ç åœ¨æŒ‡å®šé›†åˆä¸­çš„æœ€æ–°äº¤æ˜“æ—¥æœŸ"""
        try:
            collection = self.db.get_collection(collection_name)
            latest_record = collection.find_one(
                {'ts_code': ts_code},
                sort=[('trade_date', -1)]
            )
            if latest_record and 'trade_date' in latest_record:
                # ç¡®ä¿è¿”å›çš„æ˜¯datetimeå¯¹è±¡
                trade_date = latest_record['trade_date']
                if isinstance(trade_date, str):
                    return datetime.strptime(trade_date, '%Y%m%d')
                return trade_date
            return None
        except Exception as e:
            logging.error(f"åœ¨ {collection_name} ä¸­æŸ¥è¯¢ {ts_code} çš„æœ€æ–°æ—¥æœŸå¤±è´¥: {e}")
            return None

    def get_all_stock_codes(self) -> List[str]:
        """ä»æ•°æ®åº“è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç """
        try:
            # Implementation of get_all_stock_codes method
            # This method needs to be implemented based on your specific requirements
            # For now, it's left empty as the implementation is not provided in the original file or the new code block
            return []
        except Exception as e:
            logging.error(f"ä»æ•°æ®åº“è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç å¤±è´¥: {e}")
            return []

# å»¶è¿Ÿåˆå§‹åŒ–ï¼Œé¿å…å¯¼å…¥æ—¶å°±åˆ›å»ºè¿æ¥
_db_handler = None

def get_db_handler():
    """è·å–æ•°æ®åº“å¤„ç†å™¨å•ä¾‹"""
    global _db_handler
    if _db_handler is None:
        _db_handler = DBHandler()
    return _db_handler

def reset_db_handler():
    """é‡ç½®æ•°æ®åº“å¤„ç†å™¨å•ä¾‹ï¼Œå¼ºåˆ¶é‡æ–°åˆå§‹åŒ–"""
    global _db_handler
    if _db_handler is not None:
        try:
            _db_handler.__del__()  # å…³é—­ç°æœ‰è¿æ¥
        except:
            pass
    _db_handler = None
    print("ğŸ”„ æ•°æ®åº“å¤„ç†å™¨å·²é‡ç½®")

def check_database_connection():
    """æ£€æŸ¥æ•°æ®åº“è¿æ¥"""
    try:
        db_handler = get_db_handler()
        client = db_handler.client # ç›´æ¥è®¿é—® client å±æ€§
        client.server_info()  # æ£€æŸ¥è¿æ¥
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return False