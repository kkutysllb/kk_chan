#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼ è®ºåˆ†æå¼•æ“ - æ•´åˆå½¢æ€å­¦å’ŒåŠ¨åŠ›å­¦åˆ†æ
åŸºäºç¼ ä¸­è¯´ç¦…ç†è®ºçš„å®Œæ•´å®ç°ï¼Œæä¾›ä¸€ç«™å¼ç¼ è®ºåˆ†ææœåŠ¡

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å½¢æ€å­¦åˆ†æï¼šKçº¿å¤„ç†ã€åˆ†å‹è¯†åˆ«ã€ç¬”æ„å»ºã€çº¿æ®µæ„å»ºã€ä¸­æ¢æ„å»º
2. åŠ¨åŠ›å­¦åˆ†æï¼šMACDèƒŒé©°ã€ä¸€äºŒä¸‰ç±»ä¹°å–ç‚¹ã€å¤šçº§åˆ«é€’å½’å…³ç³»
3. ç»¼åˆåˆ†æï¼šèµ°åŠ¿é¢„æµ‹ã€äº¤æ˜“ä¿¡å·ç”Ÿæˆã€é£é™©è¯„ä¼°
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Dict, Optional, Tuple, Any, Union
from enum import Enum

# å½¢æ€å­¦æ¨¡å—
from models.kline import KLine, KLineList
from models.fenxing import FenXing, FenXingList
from models.bi import Bi, BiList, BiBuilder, BiConfig
from models.seg import Seg, SegList, SegBuilder, SegConfig
from models.zhongshu import ZhongShu, ZhongShuList, ZhongShuBuilder, ZhongShuConfig
from models.enums import TimeLevel, BiDirection, SegDirection, ZhongShuType

# åŠ¨åŠ›å­¦æ¨¡å—
from models.dynamics import (
    DynamicsAnalyzer, MultiLevelDynamicsAnalyzer, 
    BackChiAnalysis, BuySellPoint, BuySellPointType, BackChi,
    DynamicsConfig, MultiLevelAnalysis
)

# æ ¸å¿ƒå¤„ç†å™¨
from core.kline_processor import KlineProcessor
from config.chan_config import ChanConfig


class AnalysisLevel(Enum):
    """åˆ†æçº§åˆ«æšä¸¾"""
    BASIC = "basic"           # åŸºç¡€åˆ†æï¼šåªåšå½¢æ€å­¦
    STANDARD = "standard"     # æ ‡å‡†åˆ†æï¼šå½¢æ€å­¦ + åŠ¨åŠ›å­¦
    ADVANCED = "advanced"     # é«˜çº§åˆ†æï¼šå¤šçº§åˆ«é€’å½’å…³ç³»
    COMPLETE = "complete"     # å®Œæ•´åˆ†æï¼šæ‰€æœ‰åŠŸèƒ½ + é¢„æµ‹


@dataclass
class ChanAnalysisResult:
    """ç¼ è®ºåˆ†æç»“æœ"""
    # åŸºç¡€ä¿¡æ¯
    symbol: str
    time_level: TimeLevel
    analysis_time: datetime = field(default_factory=datetime.now)
    analysis_level: AnalysisLevel = AnalysisLevel.STANDARD
    
    # å½¢æ€å­¦ç»“æœ
    klines: KLineList = field(default_factory=KLineList)
    processed_klines: KLineList = field(default_factory=KLineList)
    fenxings: FenXingList = field(default_factory=FenXingList)
    bis: BiList = field(default_factory=BiList)
    segs: SegList = field(default_factory=SegList)
    zhongshus: ZhongShuList = field(default_factory=ZhongShuList)
    
    # åŠ¨åŠ›å­¦ç»“æœ
    backchi_analyses: List[BackChiAnalysis] = field(default_factory=list)
    buy_sell_points: List[BuySellPoint] = field(default_factory=list)
    
    # å¤šçº§åˆ«åˆ†æç»“æœ
    multi_level_results: Dict[TimeLevel, 'ChanAnalysisResult'] = field(default_factory=dict)
    level_consistency_score: float = 0.0
    
    # ç»¼åˆè¯„ä¼°
    trend_direction: Optional[str] = None    # "up", "down", "consolidation"
    trend_strength: float = 0.0              # è¶‹åŠ¿å¼ºåº¦ 0-1
    risk_level: float = 0.0                  # é£é™©ç­‰çº§ 0-1
    confidence_score: float = 0.0            # åˆ†æå¯ä¿¡åº¦ 0-1
    
    # äº¤æ˜“å»ºè®®
    recommended_action: Optional[str] = None  # "buy", "sell", "hold", "wait"
    entry_price: Optional[float] = None
    stop_loss: Optional[float] = None
    take_profit: Optional[float] = None
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–åˆ†æç»Ÿè®¡ä¿¡æ¯"""
        return {
            'symbol': self.symbol,
            'time_level': self.time_level.value,
            'analysis_level': self.analysis_level.value,
            'klines_count': len(self.klines),
            'processed_klines_count': len(self.processed_klines),
            'fenxings_count': len(self.fenxings),
            'bis_count': len(self.bis),
            'segs_count': len(self.segs),
            'zhongshus_count': len(self.zhongshus),
            'backchi_count': len(self.backchi_analyses),
            'buy_sell_points_count': len(self.buy_sell_points),
            'buy_points_count': len([p for p in self.buy_sell_points if p.point_type.is_buy()]),
            'sell_points_count': len([p for p in self.buy_sell_points if p.point_type.is_sell()]),
            'trend_direction': self.trend_direction,
            'trend_strength': self.trend_strength,
            'risk_level': self.risk_level,
            'confidence_score': self.confidence_score,
            'recommended_action': self.recommended_action
        }
    
    def get_latest_signals(self, count: int = 5) -> List[BuySellPoint]:
        """è·å–æœ€æ–°çš„ä¹°å–ç‚¹ä¿¡å·"""
        sorted_points = sorted(self.buy_sell_points, key=lambda x: x.timestamp, reverse=True)
        return sorted_points[:count]
    
    def get_active_zhongshus(self) -> List[ZhongShu]:
        """è·å–æ´»è·ƒä¸­æ¢"""
        return [zs for zs in self.zhongshus if not zs.is_finished]
    
    def has_valid_signals(self) -> bool:
        """æ˜¯å¦æœ‰æœ‰æ•ˆçš„äº¤æ˜“ä¿¡å·"""
        return (len(self.buy_sell_points) > 0 and 
                any(p.reliability > 0.5 for p in self.buy_sell_points))


class ChanEngine:
    """
    ç¼ è®ºåˆ†æå¼•æ“
    æ•´åˆå½¢æ€å­¦å’ŒåŠ¨åŠ›å­¦åˆ†æï¼Œæä¾›å®Œæ•´çš„ç¼ è®ºåˆ†ææœåŠ¡
    """
    
    def __init__(self, 
                 chan_config: Optional[ChanConfig] = None,
                 dynamics_config: Optional[DynamicsConfig] = None):
        """
        åˆå§‹åŒ–ç¼ è®ºå¼•æ“
        
        Args:
            chan_config: ç¼ è®ºåŸºç¡€é…ç½®
            dynamics_config: åŠ¨åŠ›å­¦åˆ†æé…ç½®
        """
        self.chan_config = chan_config or ChanConfig()
        self.dynamics_config = dynamics_config or DynamicsConfig()
        
        # åˆå§‹åŒ–å¤„ç†å™¨
        self.kline_processor = KlineProcessor(self.chan_config)
        self.bi_builder = BiBuilder(BiConfig())
        self.seg_builder = SegBuilder(SegConfig())
        self.zhongshu_builder = ZhongShuBuilder(ZhongShuConfig())
        
        # åˆå§‹åŒ–åŠ¨åŠ›å­¦åˆ†æå™¨
        self.dynamics_analyzer = DynamicsAnalyzer(self.dynamics_config.macd_params)
        self.multi_level_analyzer = MultiLevelDynamicsAnalyzer()
        
        # åˆ†æå†å²ç¼“å­˜
        self._analysis_cache: Dict[str, ChanAnalysisResult] = {}
    
    def analyze(self, 
               data: Union[List[Dict], KLineList],
               symbol: str,
               time_level: TimeLevel,
               analysis_level: AnalysisLevel = AnalysisLevel.STANDARD) -> ChanAnalysisResult:
        """
        æ‰§è¡Œç¼ è®ºåˆ†æ
        
        Args:
            data: Kçº¿æ•°æ®æˆ–KLineListå¯¹è±¡
            symbol: è‚¡ç¥¨ä»£ç 
            time_level: æ—¶é—´çº§åˆ«
            analysis_level: åˆ†æçº§åˆ«
            
        Returns:
            åˆ†æç»“æœ
        """
        # åˆ›å»ºç»“æœå¯¹è±¡
        result = ChanAnalysisResult(
            symbol=symbol,
            time_level=time_level,
            analysis_level=analysis_level
        )
        
        # æ•°æ®é¢„å¤„ç†
        if isinstance(data, list):
            result.klines = KLineList.from_mongo_data(data, time_level)
        else:
            result.klines = data
        
        if len(result.klines) < 10:
            raise ValueError(f"æ•°æ®é‡ä¸è¶³ï¼šéœ€è¦è‡³å°‘10æ¡Kçº¿ï¼Œå½“å‰åªæœ‰{len(result.klines)}æ¡")
        
        # æ‰§è¡Œå½¢æ€å­¦åˆ†æ
        self._perform_morphology_analysis(result)
        
        # æ ¹æ®åˆ†æçº§åˆ«æ‰§è¡Œç›¸åº”åˆ†æ
        if analysis_level in [AnalysisLevel.STANDARD, AnalysisLevel.ADVANCED, AnalysisLevel.COMPLETE]:
            self._perform_dynamics_analysis(result)
        
        if analysis_level in [AnalysisLevel.ADVANCED, AnalysisLevel.COMPLETE]:
            # å¤šçº§åˆ«åˆ†æéœ€è¦é¢å¤–æ•°æ®ï¼Œè¿™é‡Œæš‚æ—¶è·³è¿‡
            pass
        
        if analysis_level == AnalysisLevel.COMPLETE:
            self._perform_comprehensive_analysis(result)
        
        # ç¼“å­˜ç»“æœ
        cache_key = f"{symbol}_{time_level.value}_{analysis_level.value}"
        self._analysis_cache[cache_key] = result
        
        return result
    
    def analyze_multi_level(self,
                          level_data: Dict[TimeLevel, Union[List[Dict], KLineList]],
                          symbol: str) -> Dict[TimeLevel, ChanAnalysisResult]:
        """
        å¤šçº§åˆ«åˆ†æ
        
        Args:
            level_data: å„çº§åˆ«çš„Kçº¿æ•°æ®
            symbol: è‚¡ç¥¨ä»£ç 
            
        Returns:
            å„çº§åˆ«çš„åˆ†æç»“æœ
        """
        results = {}
        
        # å•ç‹¬åˆ†æå„ä¸ªçº§åˆ«
        for level, data in level_data.items():
            try:
                result = self.analyze(data, symbol, level, AnalysisLevel.STANDARD)
                results[level] = result
            except Exception as e:
                print(f"âš ï¸ {level.value}çº§åˆ«åˆ†æå¤±è´¥: {e}")
                continue
        
        # åˆ†æçº§åˆ«é—´å…³ç³»
        if len(results) >= 2:
            self._analyze_multi_level_relations(results)
        
        return results
    
    def get_trading_signals(self, result: ChanAnalysisResult) -> Dict[str, Any]:
        """
        ç”Ÿæˆäº¤æ˜“ä¿¡å·
        
        Args:
            result: åˆ†æç»“æœ
            
        Returns:
            äº¤æ˜“ä¿¡å·ä¿¡æ¯
        """
        signals = {
            'symbol': result.symbol,
            'timestamp': datetime.now(),
            'signals': [],
            'summary': {
                'total_signals': 0,
                'buy_signals': 0,
                'sell_signals': 0,
                'high_confidence_signals': 0
            }
        }
        
        # å¤„ç†ä¹°å–ç‚¹ä¿¡å·
        for point in result.buy_sell_points:
            if point.reliability >= self.dynamics_config.buy_sell_point_min_reliability:
                signal = {
                    'type': 'buy' if point.point_type.is_buy() else 'sell',
                    'point_type': str(point.point_type),
                    'price': point.price,
                    'timestamp': point.timestamp,
                    'reliability': point.reliability,
                    'strength': point.strength,
                    'confirmed': point.confirmed_by_higher_level or point.confirmed_by_lower_level
                }
                signals['signals'].append(signal)
                
                # ç»Ÿè®¡
                signals['summary']['total_signals'] += 1
                if point.point_type.is_buy():
                    signals['summary']['buy_signals'] += 1
                else:
                    signals['summary']['sell_signals'] += 1
                
                if point.reliability > 0.7:
                    signals['summary']['high_confidence_signals'] += 1
        
        # å¤„ç†èƒŒé©°ä¿¡å·
        for backchi in result.backchi_analyses:
            if backchi.is_valid_backchi():
                signal = {
                    'type': 'backchi',
                    'backchi_type': str(backchi.backchi_type),
                    'current_seg': {
                        'start_time': backchi.current_seg.start_time,
                        'end_time': backchi.current_seg.end_time,
                        'start_price': backchi.current_seg.start_price,
                        'end_price': backchi.current_seg.end_price
                    },
                    'reliability': backchi.reliability,
                    'strength_ratio': backchi.strength_ratio
                }
                signals['signals'].append(signal)
                signals['summary']['total_signals'] += 1
        
        return signals
    
    def _perform_morphology_analysis(self, result: ChanAnalysisResult) -> None:
        """æ‰§è¡Œå½¢æ€å­¦åˆ†æ"""
        # Kçº¿å¤„ç†å’Œåˆ†å‹è¯†åˆ«
        processed_klines, fenxings = self.kline_processor.process_klines(result.klines)
        result.processed_klines = processed_klines  # KlineProcessorå·²è¿”å›KLineList
        result.fenxings = fenxings  # KlineProcessorå·²è¿”å›FenXingList
        
        # æ„å»ºç¬”
        if len(fenxings) >= 2:
            bis = self.bi_builder.build_from_fenxings(fenxings.fenxings)  # ä¼ é€’fenxingåˆ—è¡¨
            result.bis = BiList(bis)
        
        # æ„å»ºçº¿æ®µ
        if len(result.bis) >= 3:
            segs = self.seg_builder.build_from_bis(result.bis.bis)
            result.segs = SegList(segs, result.time_level)
        
        # æ„å»ºä¸­æ¢
        if len(result.segs) >= 3:
            zhongshus = self.zhongshu_builder.build_from_segs(result.segs.segs)
            result.zhongshus = ZhongShuList(zhongshus)
    
    def _perform_dynamics_analysis(self, result: ChanAnalysisResult) -> None:
        """æ‰§è¡ŒåŠ¨åŠ›å­¦åˆ†æ"""
        if len(result.segs) < 3 or len(result.zhongshus) == 0:
            return
        
        # èƒŒé©°åˆ†æ
        result.backchi_analyses = self.dynamics_analyzer.analyze_backchi(
            result.segs, result.zhongshus, result.processed_klines
        )
        
        # ä¹°å–ç‚¹è¯†åˆ«
        result.buy_sell_points = self.dynamics_analyzer.identify_buy_sell_points(
            result.backchi_analyses, result.segs, result.zhongshus, result.processed_klines
        )
    
    def _perform_comprehensive_analysis(self, result: ChanAnalysisResult) -> None:
        """æ‰§è¡Œç»¼åˆåˆ†æ"""
        # è¶‹åŠ¿æ–¹å‘åˆ¤æ–­
        result.trend_direction = self._determine_trend_direction(result)
        
        # è¶‹åŠ¿å¼ºåº¦è®¡ç®—
        result.trend_strength = self._calculate_trend_strength(result)
        
        # é£é™©è¯„ä¼°
        result.risk_level = self._assess_risk_level(result)
        
        # å¯ä¿¡åº¦è¯„åˆ†
        result.confidence_score = self._calculate_confidence_score(result)
        
        # äº¤æ˜“å»ºè®®
        self._generate_trading_recommendation(result)
    
    def _determine_trend_direction(self, result: ChanAnalysisResult) -> str:
        """åˆ¤æ–­è¶‹åŠ¿æ–¹å‘"""
        if len(result.segs) < 2:
            return "consolidation"
        
        # è·å–æœ€è¿‘çš„çº¿æ®µ
        recent_segs = result.segs.segs[-3:] if len(result.segs) >= 3 else result.segs.segs
        
        up_segs = [seg for seg in recent_segs if seg.is_up]
        down_segs = [seg for seg in recent_segs if seg.is_down]
        
        if len(up_segs) > len(down_segs):
            return "up"
        elif len(down_segs) > len(up_segs):
            return "down"
        else:
            return "consolidation"
    
    def _calculate_trend_strength(self, result: ChanAnalysisResult) -> float:
        """è®¡ç®—è¶‹åŠ¿å¼ºåº¦"""
        if len(result.segs) == 0:
            return 0.0
        
        # åŸºäºçº¿æ®µå¼ºåº¦å’Œæ–¹å‘ä¸€è‡´æ€§
        avg_strength = sum(seg.strength for seg in result.segs) / len(result.segs)
        
        # æ–¹å‘ä¸€è‡´æ€§
        if result.trend_direction == "consolidation":
            direction_consistency = 0.5
        else:
            target_direction = SegDirection.UP if result.trend_direction == "up" else SegDirection.DOWN
            consistent_segs = [seg for seg in result.segs if seg.direction == target_direction]
            direction_consistency = len(consistent_segs) / len(result.segs)
        
        return (avg_strength * 0.6 + direction_consistency * 0.4)
    
    def _assess_risk_level(self, result: ChanAnalysisResult) -> float:
        """è¯„ä¼°é£é™©ç­‰çº§"""
        risk_factors = []
        
        # èƒŒé©°é£é™©
        valid_backchis = [b for b in result.backchi_analyses if b.is_valid_backchi()]
        if valid_backchis:
            avg_backchi_reliability = sum(b.reliability for b in valid_backchis) / len(valid_backchis)
            risk_factors.append(avg_backchi_reliability)
        
        # ä¸­æ¢ç¨³å®šæ€§é£é™©
        if result.zhongshus:
            avg_stability = sum(zs.stability for zs in result.zhongshus) / len(result.zhongshus)
            risk_factors.append(1.0 - avg_stability)
        
        # è¶‹åŠ¿å¼ºåº¦é£é™©
        risk_factors.append(1.0 - result.trend_strength)
        
        return sum(risk_factors) / len(risk_factors) if risk_factors else 0.5
    
    def _calculate_confidence_score(self, result: ChanAnalysisResult) -> float:
        """è®¡ç®—åˆ†æå¯ä¿¡åº¦"""
        confidence_factors = []
        
        # æ•°æ®é‡å……è¶³æ€§
        data_adequacy = min(1.0, len(result.processed_klines) / 100)
        confidence_factors.append(data_adequacy)
        
        # ç»“æ„å®Œæ•´æ€§
        structure_completeness = 0.0
        if len(result.fenxings) > 0:
            structure_completeness += 0.2
        if len(result.bis) > 0:
            structure_completeness += 0.2  
        if len(result.segs) > 0:
            structure_completeness += 0.3
        if len(result.zhongshus) > 0:
            structure_completeness += 0.3
        confidence_factors.append(structure_completeness)
        
        # ä¿¡å·è´¨é‡
        if result.buy_sell_points:
            avg_signal_reliability = sum(p.reliability for p in result.buy_sell_points) / len(result.buy_sell_points)
            confidence_factors.append(avg_signal_reliability)
        else:
            confidence_factors.append(0.5)
        
        return sum(confidence_factors) / len(confidence_factors)
    
    def _generate_trading_recommendation(self, result: ChanAnalysisResult) -> None:
        """ç”Ÿæˆäº¤æ˜“å»ºè®®"""
        # åŸºäºä¹°å–ç‚¹å’Œè¶‹åŠ¿æ–¹å‘ç”Ÿæˆå»ºè®®
        latest_points = result.get_latest_signals(3)
        
        if not latest_points:
            result.recommended_action = "wait"
            return
        
        latest_point = latest_points[0]
        
        if (latest_point.point_type.is_buy() and 
            latest_point.reliability > 0.6 and
            result.trend_direction in ["up", "consolidation"]):
            result.recommended_action = "buy"
            result.entry_price = latest_point.price
            
            # è®¾ç½®æ­¢æŸå’Œæ­¢ç›ˆ
            if result.zhongshus:
                latest_zhongshu = result.zhongshus[-1]
                result.stop_loss = latest_zhongshu.low * 0.98
                result.take_profit = latest_point.price * 1.1
            
        elif (latest_point.point_type.is_sell() and 
              latest_point.reliability > 0.6 and
              result.trend_direction in ["down", "consolidation"]):
            result.recommended_action = "sell"
            result.entry_price = latest_point.price
            
            # è®¾ç½®æ­¢æŸå’Œæ­¢ç›ˆ
            if result.zhongshus:
                latest_zhongshu = result.zhongshus[-1]
                result.stop_loss = latest_zhongshu.high * 1.02
                result.take_profit = latest_point.price * 0.9
        else:
            result.recommended_action = "hold"
    
    def _analyze_multi_level_relations(self, results: Dict[TimeLevel, ChanAnalysisResult]) -> None:
        """åˆ†æå¤šçº§åˆ«å…³ç³»"""
        levels = [TimeLevel.DAILY, TimeLevel.MIN_30, TimeLevel.MIN_5]
        
        for i, level in enumerate(levels):
            if level not in results:
                continue
            
            current_result = results[level]
            
            # è®¡ç®—çº§åˆ«ä¸€è‡´æ€§å¾—åˆ†
            consistency_factors = []
            
            # è¶‹åŠ¿æ–¹å‘ä¸€è‡´æ€§
            if i > 0:
                higher_level = levels[i-1]
                if higher_level in results:
                    if results[higher_level].trend_direction == current_result.trend_direction:
                        consistency_factors.append(0.4)
                    else:
                        consistency_factors.append(0.0)
            
            if i < len(levels) - 1:
                lower_level = levels[i+1]
                if lower_level in results:
                    if results[lower_level].trend_direction == current_result.trend_direction:
                        consistency_factors.append(0.3)
                    else:
                        consistency_factors.append(0.0)
            
            # ä¿¡å·ä¸€è‡´æ€§
            if current_result.buy_sell_points:
                consistency_factors.append(0.3)
            
            current_result.level_consistency_score = (
                sum(consistency_factors) / len(consistency_factors) if consistency_factors else 0.0
            )
    
    def get_analysis_summary(self, result: ChanAnalysisResult) -> str:
        """è·å–åˆ†ææ‘˜è¦"""
        stats = result.get_statistics()
        
        summary = f"""
ğŸ” ç¼ è®ºåˆ†ææŠ¥å‘Š - {stats['symbol']} ({stats['time_level']})
{'='*50}
ğŸ“Š å½¢æ€å­¦åˆ†æ:
  â€¢ Kçº¿å¤„ç†: {stats['klines_count']} â†’ {stats['processed_klines_count']} æ ¹
  â€¢ åˆ†å‹è¯†åˆ«: {stats['fenxings_count']} ä¸ª
  â€¢ ç¬”æ„å»º: {stats['bis_count']} ä¸ª  
  â€¢ çº¿æ®µæ„å»º: {stats['segs_count']} ä¸ª
  â€¢ ä¸­æ¢æ„å»º: {stats['zhongshus_count']} ä¸ª

ğŸ¯ åŠ¨åŠ›å­¦åˆ†æ:
  â€¢ èƒŒé©°åˆ†æ: {stats['backchi_count']} ä¸ª
  â€¢ ä¹°å–ç‚¹è¯†åˆ«: {stats['buy_sell_points_count']} ä¸ª
    - ä¹°ç‚¹: {stats['buy_points_count']} ä¸ª
    - å–ç‚¹: {stats['sell_points_count']} ä¸ª

ğŸ“ˆ ç»¼åˆè¯„ä¼°:
  â€¢ è¶‹åŠ¿æ–¹å‘: {stats['trend_direction'] or 'æœªç¡®å®š'}
  â€¢ è¶‹åŠ¿å¼ºåº¦: {stats['trend_strength']:.1%}
  â€¢ é£é™©ç­‰çº§: {stats['risk_level']:.1%}
  â€¢ å¯ä¿¡åº¦: {stats['confidence_score']:.1%}
  â€¢ äº¤æ˜“å»ºè®®: {stats['recommended_action'] or 'æš‚æ— '}
        """
        
        # æœ€æ–°ä¿¡å·
        latest_signals = result.get_latest_signals(3)
        if latest_signals:
            summary += "\nğŸš¨ æœ€æ–°äº¤æ˜“ä¿¡å·:\n"
            for i, signal in enumerate(latest_signals, 1):
                summary += f"  {i}. {signal.point_type} @{signal.price:.2f} (å¯é åº¦:{signal.reliability:.1%})\n"
        
        return summary.strip()
    
    def clear_cache(self) -> None:
        """æ¸…ç©ºåˆ†æç¼“å­˜"""
        self._analysis_cache.clear()


# ä¾¿æ·å‡½æ•°
def quick_analyze(data: Union[List[Dict], KLineList], 
                 symbol: str, 
                 time_level: TimeLevel) -> ChanAnalysisResult:
    """å¿«é€Ÿç¼ è®ºåˆ†æ"""
    engine = ChanEngine()
    return engine.analyze(data, symbol, time_level, AnalysisLevel.STANDARD)


def multi_level_analyze(level_data: Dict[TimeLevel, Union[List[Dict], KLineList]], 
                       symbol: str) -> Dict[TimeLevel, ChanAnalysisResult]:
    """å¤šçº§åˆ«ç¼ è®ºåˆ†æ"""
    engine = ChanEngine()
    return engine.analyze_multi_level(level_data, symbol)